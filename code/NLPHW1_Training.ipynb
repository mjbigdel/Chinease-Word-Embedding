{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LastCode_NLPHW1 (2).ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"code","id":"hn2V93X808iH","outputId":"5229ad36-0943-4831-96ff-68a778411f2e","executionInfo":{"status":"ok","timestamp":1555894715349,"user_tz":-120,"elapsed":5692,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":377}},"cell_type":"code","source":["!pip install tensorflow\n","# TensorFlow and tf.keras\n","# its just working with tensorflow 1.13.1, with others has problem\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n","Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.9.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n","Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n","Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1556066450467,"user_tz":-120,"elapsed":1693,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"id":"cXO7IbXUVspf","outputId":"3d89d3b7-06cf-4258-be4b-ba2c321789fe","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.13.1\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"NeNCvsKU2i-V","outputId":"fbf315e4-f6c3-4eb1-9af0-a428e911f0c9","executionInfo":{"status":"ok","timestamp":1556114154516,"user_tz":-120,"elapsed":22969,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive',force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1556117829451,"user_tz":-120,"elapsed":2465,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"id":"BB3PsCWK5R-T","outputId":"6a7e07a9-e726-4e34-c23b-a600a9f8ef21","colab":{"base_uri":"https://localhost:8080/","height":123}},"cell_type":"code","source":["!ls \"/content/gdrive/My Drive/NLPHW1\"\n","root_path = '/content/gdrive/My Drive/NLPHW1/'\n","print(root_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" 130K_best_model\t\t     'LastCode_NLPHW1 (2).ipynb'\n"," cityu_best_models\t\t      msr_best_models\n","'Copy of LastCode_NLPHW1 (2).ipynb'   pku_best_models\n"," Datasets\t\t\t      tf1.12.0TestPrediction.ipynb\n"," embedding\n","/content/gdrive/My Drive/NLPHW1/\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"_9SeAA4R1apd"},"cell_type":"markdown","source":["**imports and basic definitions**"]},{"metadata":{"colab_type":"code","id":"Xx6SdSVr9vCP","colab":{}},"cell_type":"code","source":["# Imports\n","import os\n","import re\n","import errno\n","import pickle\n","import numpy as np\n","from collections import Counter\n","import codecs\n","import tensorflow as tf\n","from tensorflow.contrib import layers\n","from tensorflow.contrib import crf\n","\n","#!pip install HanziConv\n","# from hanziconv import HanziConv\n","\n","# Added Chars to dictionary\n","START_SENT = \"گ\"\n","END_SENT = \"چ\"\n","UNK = \"ژ\"\n","PAD = \"پ\"\n","TAGB,TAGI,TAGE,TAGS=0,1,2,3\n","\n","rNUM = '(-|\\+)?\\d+((\\.|·)\\d+)?%?'\n","rENG = '[A-Za-z_.]+'\n","\n","def make_sure_path_exists(path):\n","    try:\n","        os.makedirs(path)\n","    except OSError as exception:\n","        if exception.errno != errno.EEXIST:\n","            raise\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"pU6coSb71sRQ"},"cell_type":"markdown","source":["***Create Curpus Section For Cleaning and combining datasets***"]},{"metadata":{"colab_type":"code","id":"kaepb4bw9z41","colab":{}},"cell_type":"code","source":["# ===-----------------------------------------------------------------------===\n","# CreateCurpus\n","# ===-----------------------------------------------------------------------===\n","\n","# Function for converting traditional chinease to simplefied one.\n","def traditional_to_siplefied(src_file, des_file, encode='UTF-8'):\n","   with open(src_file, encoding=encode) as src_file, open(des_file, 'w', encoding=encode) as des_file:\n","       for line in src_file:                    \n","           rstring = HanziConv.toSimplified(line)                        \n","           des_file.write(rstring)\n","\n","# function for combining datasets as one large set.\n","def combine_files(files, out):\n","    if os.path.exists(out):\n","        os.remove(out)\n","    with open(out, 'a', encoding='utf-8') as out:\n","        for file_num in range(len(files)): \n","            file_add = root_path+'Datasets/{}.utf8'.format(files[file_num])\n","            print(file_add)\n","            with open(file_add, encoding='utf-8') as file_add:\n","                for line in file_add:\n","                    out.write(line) \n","            if(file_num != len(files)-1): \n","                print(\"new line\")\n","                out.write('\\n')    \n","    print('\\nAll data Saved as All_datasets file')\n","                \n","\n","\n","# Function for cleaning file, make charachters better and spaces standard space.\n","def clean_data(src_file, des_file, encode='UTF-8'):\n","    with open(src_file, encoding=encode) as src_file, open(des_file, 'w', encoding=encode) as des_file:\n","        sentences=[]\n","        for line in src_file: \n","            # cleaning input\n","            rstring = \"\"\n","            for uchar in line:\n","                inside_code = ord(uchar)\n","                if inside_code == 12288:\n","                    inside_code = 32\n","                elif 65281 <= inside_code <= 65374:\n","                    inside_code -= 65248\n","            \n","                rstring += chr(inside_code)      \n","            \n","            sent_words = rstring.split()\n","            \n","            new_sent_words = []\n","            \n","            for word in sent_words:\n","                word = re.sub('\\s+', '', word, flags=re.U)    \n","                new_sent_words.append(word)\n","            \n","            sentences.append(new_sent_words)\n","        for sent_num in range(len(sentences)):\n","           # if(sent_num != len(sentences)-1):\n","            des_file.write(' '.join(sentences[sent_num]) + '\\n') \n","            #else:\n","             #   des_file.write(' '.join(sentences[sent_num])) \n","\n","\n","def cleaning_datasets(all_datasets,with_space =True):    \n","    make_sure_path_exists(root_path+'Datasets/cleaned_data/{}'.format(all_datasets))\n","    make_sure_path_exists(root_path+'Datasets/cleaned_data/{}'.format(all_datasets) + '/raw')\n","    clean_data(root_path+'Datasets/training/{}_training.utf8'.format(all_datasets), root_path+'Datasets/cleaned_data/{}/raw/train.utf8'.format(all_datasets))\n","    clean_data(root_path+'Datasets/gold/{}_test_gold.utf8'.format(all_datasets), root_path+'Datasets/cleaned_data/{}/raw/test.utf8'.format(all_datasets))   \n","\n","def remove_spaces(src_file, des_file, encode='UTF-8'):\n","    with open(src_file, encoding=encode) as src_file, open(des_file, 'w', encoding=encode) as des_file:\n","        for line in src_file: \n","            # cleaning input                     \n","            sent_words = line.split()                             \n","            sentence = ''.join(sent_words) + '\\n'\n","            des_file.write(sentence)     \n","\n","\n","# function for creating BIES tag\n","def bies_tag(input_file, output_file):\n","    with open(input_file, encoding='utf-8') as input_data, open(output_file, 'w', encoding='utf-8') as output_data:\n","        for line in input_data:\n","            word_list = line.strip().split()\n","            tag_list = ''\n","            for word in word_list:\n","                if len(word) == 1:\n","                    tag_list +='S'\n","                else:\n","                    tag_list+='B'\n","                    for w in word[1:len(word) - 1]:\n","                        tag_list += 'I'\n","                    tag_list += 'E'            \n","            tag_list += '\\n'\n","            #print(tag_list)\n","            #print(line)\n","            output_data.write(tag_list)\n","            \n","def make_bies(all_datasets):    \n","    make_sure_path_exists(root_path+'Datasets/cleaned_data/{}'.format(all_datasets))\n","    make_sure_path_exists(root_path+'Datasets/cleaned_data/{}'.format(all_datasets) + '/bies')\n","    bies_tag(root_path+'Datasets/training/{}_training.utf8'.format(all_datasets), root_path+'Datasets/cleaned_data/{}/bies/train.utf8'.format(all_datasets))\n","    bies_tag(root_path+'Datasets/gold/{}_test_gold.utf8'.format(all_datasets), root_path+'Datasets/cleaned_data/{}/bies/test.utf8'.format(all_datasets))\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1556046496093,"user_tz":-120,"elapsed":1609,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"id":"pDO-_wDx4sn2","outputId":"0a82c4d4-aba0-48ad-8456-0c3dea0ab6a9","colab":{"base_uri":"https://localhost:8080/","height":340}},"cell_type":"code","source":["# create curpus from training and gold dataset files, it gives us one file \n","#containing all training sets in single file and all gold_test set files in one another file\n","print('create_curpus started')    \n","\n","#*** traditional to simplefied converting ====================================\n","\n","#traditional_to_siplefied('Datasets/training/as_training.utf8','Datasets/training/simple_as_training.utf8')\n","#traditional_to_siplefied('Datasets/training/cityu_training.utf8','Datasets/training/simple_cityu_training.utf8')\n","#traditional_to_siplefied('Datasets/gold/cityu_test_gold.utf8','Datasets/gold/simple_cityu_test_gold.utf8')\n","#traditional_to_siplefied('Datasets/gold/as_test_gold.utf8','Datasets/gold/simple_as_test_gold.utf8')\n","\n","\n","#*** combining all dataset in one file =====================================\n","\n","train_files = ['training/pku_training','training/msr_training','training/simple_cityu_training','training/simple_as_training']\n","combine_files(train_files ,root_path+'Datasets/training/All_datasets_training.utf8')        \n","\n","gold_files = ['gold/pku_test_gold','gold/msr_test_gold','gold/simple_cityu_test_gold','gold/simple_as_test_gold']\n","combine_files(gold_files ,root_path+'Datasets/gold/All_datasets_test_gold.utf8')\n","\n","# End ==========================================================================================================\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["create_curpus started\n","/content/gdrive/My Drive/NLPHW1/Datasets/training/pku_training.utf8\n","new line\n","/content/gdrive/My Drive/NLPHW1/Datasets/training/msr_training.utf8\n","new line\n","/content/gdrive/My Drive/NLPHW1/Datasets/training/simple_cityu_training.utf8\n","new line\n","/content/gdrive/My Drive/NLPHW1/Datasets/training/simple_as_training.utf8\n","\n","All data Saved as All_datasets file\n","/content/gdrive/My Drive/NLPHW1/Datasets/gold/pku_test_gold.utf8\n","new line\n","/content/gdrive/My Drive/NLPHW1/Datasets/gold/msr_test_gold.utf8\n","new line\n","/content/gdrive/My Drive/NLPHW1/Datasets/gold/simple_cityu_test_gold.utf8\n","new line\n","/content/gdrive/My Drive/NLPHW1/Datasets/gold/simple_as_test_gold.utf8\n","\n","All data Saved as All_datasets file\n"],"name":"stdout"}]},{"metadata":{"id":"g2d2q_wNiF9Q","colab_type":"code","colab":{}},"cell_type":"code","source":["#*** some cleaning in dataset and remove spaces if there is any ===================\n","# All data Toghether for making Embedding and ngram2id files.\n","cleaning_datasets('All_datasets')\n","cleaning_datasets('pku')\n","cleaning_datasets('msr')\n","cleaning_datasets('simple_cityu')\n","cleaning_datasets('simple_as')\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yb4xNP43iIEE","colab_type":"code","outputId":"6218cbdc-49e6-462a-84fd-c642b7b9436a","executionInfo":{"status":"ok","timestamp":1556046563777,"user_tz":-120,"elapsed":59323,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#*** making bies file ===================    \n","make_bies('All_datasets')  \n","make_bies('pku')    \n","make_bies('msr') \n","make_bies('simple_cityu') \n","make_bies('simple_as') \n","#*** remove space from data =================== \n","#remove_spaces('Datasets/All_datasets/raw/train.utf8', 'Datasets/All_datasets/raw/no_space_train.utf8')\n","#remove_spaces('Datasets/All_datasets/raw/test.utf8', 'Datasets/All_datasets/raw/no_space_test.utf8')\n","\n","print('create_curpus all finished')    \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["create_curpus all finished\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"MQOE6XSr0iFO","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"44ont68h2G1Y"},"cell_type":"markdown","source":["***Preprocessing Section For creating BIES files and Making Dataset Ready For Tensorflow Model***\n","\n","\n","```\n","# pkl file of all data created and saved for any further use of data.\n","```\n","\n"]},{"metadata":{"colab_type":"code","id":"SoJYJT0o1UJF","colab":{}},"cell_type":"code","source":["# ==========================================================================================================\n","# PreProcessing\n","# ==========================================================================================================\n","\n","#get dictionary from characters and bigrams and trigrams to id    \n","def get_ngram2id(filename,bigram_words,trigram_words,fourgram_words,m_f_bigram,m_f_3gram,m_f_4gram):\n","    # Adding some chars that we define as start sentence, end sentence, padding and UNK.\n","    x=[UNK,PAD,START_SENT,END_SENT]\n","    # gets unigrams from dataset\n","    with codecs.open(filename,'r','utf-8') as f:        \n","        for line in f:\n","            line = line.strip().split()\n","            for uchar in line:                \n","                x.extend(uchar)\n","    # gets bigrams from saved bigrams of dataset\n","    bigrams=[]\n","    if bigram_words is not None:\n","        with codecs.open(bigram_words,'r','utf-8') as f:\n","            for line in f:\n","                com=line.strip().split()\n","                if int(com[1])>m_f_bigram:\n","                    bigrams.append(com[0])\n","    x.extend(bigrams)\n","    \n","    # gets trigrams from saved trigrams of dataset\n","    trigram=[]\n","    if trigram_words is not None:\n","        with codecs.open(trigram_words,'r','utf-8') as f:\n","            for line in f:\n","                com=line.strip().split()\n","                if int(com[1])>m_f_3gram:                \n","                    trigram.append(com[0])\n","    x.extend(trigram)\n","    # gets fourgrams from saved trigrams of dataset\n","    fourgram=[]\n","    if fourgram_words is not None:\n","        with codecs.open(fourgram_words,'r','utf-8') as f:\n","            for line in f:\n","                com=line.strip().split() \n","                if int(com[1])>m_f_4gram:\n","                    fourgram.append(com[0])\n","    x.extend(fourgram)\n","    \n","    \n","    counter = Counter(x)    \n","    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n","    words, _ = list(zip(*count_pairs))\n","    ngram2id = dict(zip(words, range(len(words))))\n","    return ngram2id\n","\n","#convert words to tag_id for training set labels\n","def word2tag_id(word):\n","    if len(word)==1:\n","        return [TAGS]\n","    if len(word)==2:\n","        return [TAGB,TAGE]\n","    tag_id=[]\n","    tag_id.append(TAGB)\n","    for i in range(1,len(word)-1):\n","        tag_id.append(TAGI)\n","    tag_id.append(TAGE)\n","    return tag_id\n","\n","# getting ngrams function\n","def ngram(ustr,n=2):\n","    ngram_list=[]\n","    for i in range(len(ustr)-n+1):\n","        ngram_list.append(ustr[i:i+n])\n","    return ngram_list\n","\n","# getting and saving ngrams function as pkl file\n","def save_ngram_words(src_dataset,dst_dataset,window_size=2):\n","    words=dict()\n","    with codecs.open(src_dataset,'r','utf-8') as f:\n","        for line in f:\n","            line=re.sub('\\s+','',line.strip())\n","            for word in ngram(line,window_size):\n","                words[word]=words.get(word,0)+1\n","    with codecs.open(dst_dataset,'w','utf-8') as f:\n","        len(words)\n","        i = 1\n","        for k,v in words.items():             \n","            if(i!=len(words)):\n","                f.write(k+' '+str(v)+'\\n')\n","                i = i+1\n","            else:\n","                f.write(k+' '+str(v))\n","\n","# getting training data function with unigram, bigram, trigrams and fourgram (list of 14 data for every character)\n","def get_train_data(filename,ngrams2id, usebigram, usetrigram,usefourgram):   \n","    x,y=[],[]\n","    with codecs.open(filename,'r','utf-8') as f:\n","        # for every line we split and then tag every word with proper id.\n","        for line in f:\n","            word_list=line.strip().split()\n","            line_y=[]\n","            line_x=[]\n","            for word in word_list:\n","                line_y.extend(word2tag_id(word))\n","            y.append(line_y)\n","            # for every line we remove spaces and then assume every 5 (2 left char and 2 right char)\n","            # char as a new context, for every context we also calculate bigram and trigram and add them too\n","            line=re.sub(u'\\s+','',line.strip())\n","            contexs=window(line)\n","            for contex in contexs:\n","                charx=[]\n","                #contex window\n","                charx.extend([ngrams2id.get(c,ngrams2id[UNK]) for c in contex])\n","                #bigram feature\n","                if usebigram:\n","                    charx.extend([ngrams2id.get(bigram, ngrams2id[UNK]) for bigram in ngram(contex,2)])\n","                #bigram feature\n","                if usetrigram:\n","                    charx.extend([ngrams2id.get(trigram, ngrams2id[UNK]) for trigram in ngram(contex,3)])\n","                #bigram feature\n","                if usefourgram:\n","                    charx.extend([ngrams2id.get(fourgram, ngrams2id[UNK]) for fourgram in ngram(contex,4)])\n","                line_x.append(charx)\n","            x.append(line_x)\n","            assert len(line_x)==len(line_y)\n","    return x,y\n","\n","# window return sentence as list of 5 length context, for every word we are \n","# gettnig 4 neighbour, 2 left and 2 right for having more training data.\n","def window(ustr,left=2,right=2):\n","    sent=''\n","    for i in range(left):\n","        sent+=START_SENT\n","    sent+=ustr\n","    for i in range(right):\n","        sent+=END_SENT\n","    windows=[]\n","    for i in range(len(ustr)):\n","        windows.append(sent[i:i+left+right+1])\n","    return windows\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"2MFXxQWW7c2Q","colab":{}},"cell_type":"code","source":["# get ngrams2id and id2ngram\n","FILE_FOR_NGRAM = 'All_datasets'\n","ALL_TRAIN_FILENAME=root_path+'Datasets/cleaned_data/{}/raw/train.utf8'.format(FILE_FOR_NGRAM)\n","TEST_FILENAME=root_path+'Datasets/cleaned_data/{}/raw/test.utf8'.format(FILE_FOR_NGRAM)\n","BIGRAM_FILENAME = root_path+'Datasets/cleaned_data/{}/raw/train_bigram.utf8'.format(FILE_FOR_NGRAM)\n","TRIGRAM_FILENAME = root_path+'Datasets/cleaned_data/{}/raw/train_trigram.utf8'.format(FILE_FOR_NGRAM)\n","FOURGRAM_FILENAME = root_path+'Datasets/cleaned_data/{}/raw/train_fourgram.utf8'.format(FILE_FOR_NGRAM)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"4Pfcv1Nm4eqK","colab":{}},"cell_type":"code","source":["# bigrams \n","save_ngram_words(ALL_TRAIN_FILENAME, BIGRAM_FILENAME, 2)\n","\n","# Trigram\n","save_ngram_words(ALL_TRAIN_FILENAME, TRIGRAM_FILENAME, 3)\n","\n","# fourgram\n","save_ngram_words(ALL_TRAIN_FILENAME, FOURGRAM_FILENAME, 4)\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"tGmJ9FcKP3ZM","colab":{}},"cell_type":"code","source":["m_f_4gram = 8\n","m_f_3gram = 3\n","m_f_bigram = 0\n","ngrams2id = get_ngram2id(ALL_TRAIN_FILENAME, BIGRAM_FILENAME, TRIGRAM_FILENAME,FOURGRAM_FILENAME,m_f_bigram,m_f_3gram,m_f_4gram)\n","PAD_ID = ngrams2id[PAD]"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"WXWWgkPFQe8J","outputId":"cfa7ed18-20d4-40ac-dd24-3faac6deab20","executionInfo":{"status":"ok","timestamp":1556117905214,"user_tz":-120,"elapsed":56213,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["print(len(ngrams2id))\n","print(PAD_ID)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1773043\n","69977\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1556047663176,"user_tz":-120,"elapsed":1380,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"id":"qTWo57Ow0o-D","outputId":"4e07440c-9fd5-4674-fdc3-96aff63928be","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["##saving All data ngrams2id as pkl file.\n","make_sure_path_exists(os.path.dirname(root_path+'Datasets/output_{}_ngram2id750K'.format(FILE_FOR_NGRAM)))\n","print('Saving dataset to {}'.format(root_path+'Datasets/output_{}_ngram2id750K'.format(FILE_FOR_NGRAM)))  \n","\n","output_ngram2id = {}    \n","output_ngram2id[\"ngrams2id\"] = ngrams2id\n","\n","with open(root_path+'Datasets/output_{}_ngram2id750K.pkl'.format(FILE_FOR_NGRAM), \"wb\") as outfile:\n","    pickle.dump(output_ngram2id, outfile)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Saving dataset to /content/gdrive/My Drive/NLPHW1/Datasets/output_All_datasets_ngram2id750K\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"I0kZDjHOooRX","colab":{}},"cell_type":"code","source":["# Because of the limitation of colab I decided to train model sequentially for each dataset\n","# I load each dataaset in different time and train model then save that and restart colab session\n","# and load another dataset and model and train that and ... .\n","\n","def separate_datasets_for_train(file_name):\n","    TRAIN_FILENAME=root_path+'Datasets/cleaned_data/{}/raw/train.utf8'.format(file_name)   \n","    TEST_FILENAME=root_path+'Datasets/cleaned_data/{}/raw/test.utf8'.format(file_name)\n","    \n","    # getting the train, test and dev data in proper format.\n","    train_x, train_y = get_train_data(TRAIN_FILENAME,ngrams2id, usebigram=True, usetrigram = True,usefourgram = True)\n","    test_x, test_y = get_train_data(TEST_FILENAME, ngrams2id, usebigram=True, usetrigram = True,usefourgram = True)\n","\n","    # Train and Dev split\n","    from sklearn.model_selection import train_test_split\n","    train_x, dev_x, train_y, dev_y = train_test_split(train_x, train_y, test_size=0.05, random_state=42)\n","\n","    print(\"size of train data ....\")\n","    print(len(train_x))\n","    print(len(train_x[0]))\n","    print(len(train_x[0][0]))\n","    print(\"size of dev data ....\")\n","    print(len(dev_x))\n","    print(len(dev_x[0]))\n","    print(len(dev_x[0][0]))\n","    print(\"size of test data ....\")\n","    print(len(test_x))\n","    print(len(test_x[0]))\n","    print(len(test_x[0][0]))        \n","    \n","    return train_x, train_y, dev_x, dev_y, test_x, test_y\n","  \n","def save_pkl_datasets(file_name):\n","  # saving All data as pkl file.\n","    SAVED_ADD = root_path+'Datasets/output_{}_train_test'.format(file_name)    \n","    make_sure_path_exists(os.path.dirname(SAVED_ADD))\n","    print('Saving dataset to {}'.format(SAVED_ADD))    \n","\n","    output_train_test = {}    \n","\n","    output_train_test[\"train_x\"] = train_x\n","    output_train_test[\"train_y\"] = train_y\n","    output_train_test[\"dev_x\"] = dev_x\n","    output_train_test[\"dev_y\"] = dev_y\n","    output_train_test[\"test_x\"] = test_x\n","    output_train_test[\"test_y\"] = test_y\n","    \n","    with open(root_path+'Datasets/output_{}_train_test.pkl'.format(file_name), \"wb\") as outfile:\n","        pickle.dump(output_train_test, outfile)\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"-Mo0jS-A1PrU","outputId":"c6083353-7151-405e-f471-61d8b9519fcb","executionInfo":{"status":"ok","timestamp":1556067684783,"user_tz":-120,"elapsed":25626,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"cell_type":"code","source":["# create train, test and dev sets and saving them as pkl file for further loading and making subset from them.\n","\n","datasetname = 'pku' # 'msr' 'simple_cityu' 'simple_as' 'All_datasets'\n","train_x, train_y, dev_x, dev_y, test_x, test_y = separate_datasets_for_train(datasetname)\n","\n","save_pkl_datasets(datasetname)\n","\n","subset_train = 30000 # Put number of subset data you want for train\n","subset_dev= 1000\n","subset_test= 1000\n","\n","train_x = train_x#[slice(0, subset_train)]\n","train_y = train_y#[slice(0, subset_train)]  \n","dev_x = dev_x#[slice(0, subset_dev)]\n","dev_y = dev_y#[slice(0, subset_dev)]\n","test_x = test_x#[slice(0, subset_test)]\n","test_y = test_y#[slice(0, subset_test)]\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["size of train data ....\n","18103\n","19\n","14\n","size of dev data ....\n","953\n","150\n","14\n","size of test data ....\n","1945\n","21\n","14\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"RyJhfHrT2Gk0","outputId":"e5526a5a-b70b-4a00-f8ac-2dc71f69b82f","executionInfo":{"status":"ok","timestamp":1556067807054,"user_tz":-120,"elapsed":36012,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"cell_type":"code","source":["# code for getting concatenation of subsets of all 4 datasets.\n","\n","train_x, train_y, dev_x, dev_y, test_x, test_y = [],[],[],[],[],[]\n","\n","train_x1, train_y1, dev_x1, dev_y1, test_x1, test_y1 = separate_datasets_for_train('pku')\n","\n","# Adding All pku 18000\n","train_x += train_x1\n","train_y += train_y1\n","dev_x += dev_x1\n","dev_y += dev_y1\n","test_x += test_x1\n","test_y += test_y1\n","\n","# adding 30000 of msr\n","train_x1, train_y1, dev_x1, dev_y1, test_x1, test_y1 = separate_datasets_for_train('msr')\n","\n","subset_train = 30000 # Put number of subset data you want for train\n","subset_dev= 1000\n","\n","train_x1 = train_x1[slice(0, subset_train)]\n","train_y1 = train_y1[slice(0, subset_train)]  \n","dev_x1 = dev_x1[slice(0, subset_dev)]\n","dev_y1 = dev_y1[slice(0, subset_dev)]\n","\n","train_x += train_x1\n","train_y += train_y1\n","dev_x += dev_x1\n","dev_y += dev_y1\n","test_x += test_x1\n","test_y += test_y1\n","\n","# adding 30000 of simple_cityu\n","train_x1, train_y1, dev_x1, dev_y1, test_x1, test_y1 = separate_datasets_for_train('simple_cityu')\n","\n","subset_train = 30000 # Put number of subset data you want for train\n","subset_dev= 1000\n","\n","train_x1 = train_x1[slice(0, subset_train)]\n","train_y1 = train_y1[slice(0, subset_train)]  \n","dev_x1 = dev_x1[slice(0, subset_dev)]\n","dev_y1 = dev_y1[slice(0, subset_dev)]\n","  \n","train_x += train_x1\n","train_y += train_y1\n","dev_x += dev_x1\n","dev_y += dev_y1\n","test_x += test_x1\n","test_y += test_y1\n","\n","\n","# Adding 50000 of simple_as\n","train_x1, train_y1, dev_x1, dev_y1, test_x1, test_y1 = separate_datasets_for_train('simple_as')\n","\n","subset_train = 50000 # Put number of subset data you want for train\n","subset_dev= 1000\n","\n","train_x1 = train_x1[slice(0, subset_train)]\n","train_y1 = train_y1[slice(0, subset_train)]  \n","dev_x1 = dev_x1[slice(0, subset_dev)]\n","dev_y1 = dev_y1[slice(0, subset_dev)]\n","  \n","train_x += train_x1\n","train_y += train_y1\n","dev_x += dev_x1\n","dev_y += dev_y1\n","test_x += test_x1\n","test_y += test_y1\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["size of train data ....\n","50368\n","7\n","14\n","size of dev data ....\n","2651\n","38\n","14\n","size of test data ....\n","1493\n","15\n","14\n"],"name":"stdout"}]},{"metadata":{"id":"-TLFm7yAoRer","colab_type":"code","colab":{}},"cell_type":"code","source":["# overall for last model I'm using concatenation of 130K data fror train and for better results \n","# I shuffled train data for getting good distribution of all 4 datasets\n","import random\n","\n","mapIndexPosition = list(zip(train_x, train_y))\n","random.shuffle(mapIndexPosition)\n","train_x, train_y = zip(*mapIndexPosition)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cDsqFjRu2snR","colab_type":"code","outputId":"a8d074f5-fad9-4f95-823e-ddc53e06bcaa","executionInfo":{"status":"ok","timestamp":1556118139519,"user_tz":-120,"elapsed":577,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"cell_type":"code","source":["print(\"size of train data ....\")\n","print(len(train_x))\n","print(len(train_x[0]))\n","print(len(train_x[0][0]))\n","print(\"size of dev data ....\")\n","print(len(dev_x))\n","print(len(dev_x[0]))\n","print(len(dev_x[0][0]))\n","print(\"size of test data ....\")\n","print(len(test_x))\n","print(len(test_x[0]))\n","print(len(test_x[0][0]))        \n","\n","# save_pkl_datasets('concat_130k')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["size of train data ....\n","82577\n","19\n","14\n","size of dev data ....\n","4347\n","43\n","14\n","size of test data ....\n","3985\n","13\n","14\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"Iv1O9PWj2xvR"},"cell_type":"markdown","source":["**Training Basec Functions**\n","\n","\n","*   Defning Padding Functions\n","*   Defining Functions for Number of Hits in Every Batch\n","*   Retriev All Needed Data From PKL File.\n","*   Train, Dev Split With sklearn traing_test_split function with Shuffle\n","\n","\n","\n","\n"]},{"metadata":{"colab_type":"code","id":"uAZKUpCH4UUa","outputId":"04b353b8-07c6-4b46-c047-08b51df4b3b5","executionInfo":{"status":"ok","timestamp":1556066573195,"user_tz":-120,"elapsed":3939,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Retriev word_embeddings and PAD word id from Saved pkl File\n","FILE_FOR_NGRAM = 'All_datasets'\n","ngrams2id = pickle.load(open(root_path+'Datasets/output_{}_ngram2id750K.pkl'.format(FILE_FOR_NGRAM), \"rb\"))[\"ngrams2id\"]\n","print(len(ngrams2id))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["743480\n"],"name":"stdout"}]},{"metadata":{"id":"vI5nxu5J_HT7","colab_type":"code","colab":{}},"cell_type":"code","source":["# use pretrained embeddings function, for chars we are using pretrain file and for bigram, trigram \n","# and fourgram we are using mean of embeddings of all unigrams of them\n","\n","def reading_pretrained_embeddings(filename, ngrams2id):\n","    # Reading Pretrained Embeddings from file\n","    pretrain_embeddigs = {}\n","    with codecs.open(filename, \"r\", \"utf-8\") as f:\n","        for line in f:\n","            pre_train = line.split()\n","            if len(pre_train) > 2:\n","                word = pre_train[0]\n","                if word in ngrams2id:\n","                    vec = pre_train[1:]\n","                    pretrain_embeddigs[word] = vec                \n","    \n","    print(\"pretrained embedding files reading finished ...\")\n","    # making embeddings for all ngrams2id.\n","    embedding_dim = len(next(iter(pretrain_embeddigs.values())))\n","    out_of_vocab = 0\n","    out = np.ones((len(ngrams2id), embedding_dim))\n","    for ngram in ngrams2id.keys():\n","        if len(ngram) == 1:\n","            if ngram in pretrain_embeddigs.keys():        \n","                out[ngrams2id[ngram]]=np.array(pretrain_embeddigs[ngram])\n","            else:\n","                out_of_vocab+=1\n","                np.random.uniform(-0.5, 0.5, embedding_dim)\n","    for ngram in ngrams2id.keys():        \n","        #embedding for bigrams\n","        if len(ngram) == 2:            \n","            out[ngrams2id[ngram]]= (out[ngrams2id[ngram[0]]]+out[ngrams2id[ngram[1]]])/2\n","        #embedding for trigrams\n","        if len(ngram) == 3:\n","            out[ngrams2id[ngram]]= (out[ngrams2id[ngram[0]]]+out[ngrams2id[ngram[1]]]+out[ngrams2id[ngram[2]]])/3\n","        #embedding for fourgrams\n","        if len(ngram) == 4:\n","            out[ngrams2id[ngram]]= (out[ngrams2id[ngram[0]]]+out[ngrams2id[ngram[1]]]+out[ngrams2id[ngram[2]]]+out[ngrams2id[ngram[3]]])/4               \n","    print('out_of_vocab characters: %d' % (out_of_vocab) )         \n","    return out,out_of_vocab\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"sE1009r-Qcl8","outputId":"350aa334-fb58-4436-c6e5-d74d6c51dfaf","executionInfo":{"status":"ok","timestamp":1556118166081,"user_tz":-120,"elapsed":9989,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["# get ngrams2ids's pretrained embeddings\n","word_embeddings, out_of_vocab = reading_pretrained_embeddings(root_path+'embedding/character.vec', ngrams2id)\n","PAD_ID = ngrams2id[PAD]\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["pretrained embedding files reading finished ...\n","out_of_vocab characters: 380\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1556118166082,"user_tz":-120,"elapsed":9406,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"id":"kA0hkd7mRHvZ","outputId":"fff9d609-030a-4f45-da44-6675a9a99319","colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["print(PAD_ID)\n","print(len(word_embeddings))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["69977\n","1773043\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"tOC_Ilx5H488","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"3K4B-iAR4SIe","outputId":"f3c34c84-5f83-4a83-a34a-cf94801e1254","executionInfo":{"status":"ok","timestamp":1556046682146,"user_tz":-120,"elapsed":38273,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# #Retriev train, test data from pkl files\n","\n","# FILE_NAME = 'pku'\n","\n","# TRAIN_FILE_ADD = root_path+'Datasets/output_{}_train_test.pkl'.format(FILE_NAME)\n","\n","# subset_train = 1000 # Put number of subset data you want for train\n","# subset_dev= 100\n","# subset_test= 1000\n","\n","# train_x = pickle.load(open(TRAIN_FILE_ADD, \"rb\"))[\"train_x\"][slice(0, subset_train)]\n","# train_y = pickle.load(open(TRAIN_FILE_ADD, \"rb\"))[\"train_y\"][slice(0, subset_train)]  \n","# dev_x = pickle.load(open(TRAIN_FILE_ADD, \"rb\"))[\"dev_x\"][slice(0, subset_dev)]\n","# dev_y = pickle.load(open(TRAIN_FILE_ADD, \"rb\"))[\"dev_y\"][slice(0, subset_dev)]\n","# test_x = pickle.load(open(TRAIN_FILE_ADD, \"rb\"))[\"test_x\"][slice(0, subset_test)]\n","# test_y = pickle.load(open(TRAIN_FILE_ADD, \"rb\"))[\"test_y\"][slice(0, subset_test)]\n","\n","# print(len(train_x))\n","# print(len(dev_x))\n","# print(len(test_x))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1000\n","100\n","1000\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"wFcGwOG76mED","colab":{}},"cell_type":"code","source":["# #Retriev All train, test data from pkl files\n","# FILE_NAME = ['pku','msr','simple_cityu','simple_as']\n","\n","# train_x, train_y, dev_x, dev_y, test_x, test_y = [],[],[],[],[],[]\n","\n","# for file in FILE_NAME:\n","#     TRAIN_FILE_ADD = root_path+'Datasets/output_{}_train_test.pkl'.format(file)\n","#     train_test_file = pickle.load(open(TRAIN_FILE_ADD, \"rb\"))\n","#     train_x += train_test_file[\"train_x\"]\n","#     train_y += train_test_file[\"train_y\"]\n","#     dev_x += train_test_file[\"dev_x\"]\n","#     dev_y += train_test_file[\"dev_y\"]\n","#     test_x += train_test_file[\"test_x\"]\n","#     test_y += train_test_file[\"test_y\"]\n","   \n","# print(len(train_x))\n","# print(len(train_x[0]))\n","# print(len(train_x[0][0]))\n","\n","# print(len(dev_x))\n","# print(len(dev_x[0]))\n","# print(len(dev_x[0][0]))\n","\n","# print(len(test_x))\n","# print(len(test_x[0]))\n","# print(len(test_x[0][0]))\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"Zw9f64_h3ovg"},"cell_type":"markdown","source":["**TensorFlow Model Creating**\n","\n","*   pre_trained Embedding is used.\n","*   Bidirectional LSTM with Stacked RNN Cells is Used.\n","*   Loss is negative log_likelihood and gradiant.\n","\n"]},{"metadata":{"colab_type":"code","id":"2HzY_HYgtD7s","colab":{}},"cell_type":"code","source":["# ===-----------------------------------------------------------------------===\n","# Trainig Section\n","# ===-----------------------------------------------------------------------===\n","\n","# function for add padding for train_y in every batch based on maximum length of sentence in that batch\n","# this method boost the performance of running.\n","def padding(X,padding_word):\n","\tmax_len = 0\n","\tfor x in X:\n","\t\tif len(x) > max_len:\n","\t\t\tmax_len = len(x)\n","\tpadded_X = np.ones((len(X), max_len), dtype=np.int32) * padding_word\n","\tfor i in range(len(X)):\n","\t\tfor j in range(len(X[i])):\n","\t\t\tpadded_X[i, j] = X[i][j]\n","\treturn padded_X\n","\n","# padding function for train_x\n","def padding3(X,padding_word):\n","\tmax_len = 0\n","\tfor x in X:\n","\t\tif len(x) > max_len:\n","\t\t\tmax_len = len(x)\n","\tpadded_X = np.ones((len(X), max_len,14), dtype=np.int32) * padding_word\n","\tfor i in range(len(X)):\n","\t\tfor j in range(len(X[i])):\n","\t\t\tpadded_X[i, j] = X[i][j]\n","\treturn padded_X\n","\n","# function for calculating umber of hits and number of all predictions.\n","def number_of_batch_hits(y_batch_pred,y_batch_true):\n","    num_hits = 0\n","    num_all_chars = 0    \n","    for i in range(len(y_batch_true)):\n","        for j in range(len(y_batch_true[i])):\n","            num_all_chars = num_all_chars+1\n","            if y_batch_pred[i][j] == y_batch_true[i][j]:\n","                num_hits = num_hits+1    \n","    return num_hits, num_all_chars\n","\n","# ----------------- Add Summary Function ------------------------------------------\n","def add_summary(writer, name, value, global_step):\n","    summary = tf.Summary(value=[tf.Summary.Value(tag=name, simple_value=value)])\n","    writer.add_summary(summary, global_step=global_step)\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"mD8hzD7hmeft","outputId":"bb0fb32f-6c87-4179-c134-3323540dccd2","executionInfo":{"status":"ok","timestamp":1556118168001,"user_tz":-120,"elapsed":1245,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["# we are using pretrained embedding\n","VOCAB_SIZE =  word_embeddings.shape[0]\n","WORD_EMBEDDING_DIM = word_embeddings.shape[1]\n","print(WORD_EMBEDDING_DIM)\n","print(VOCAB_SIZE)\n","\n","# some Basic Hyper parameters\n","NUM_EPOCHS = 20\n","BATCH_SIZE = 16\n","HIDDEN_LAYER_DIM = 128\n","LEARNING_RATE = 0.001\n","NUM_CLASSES = 4\n","L2_REGU_LAMBDA=0.0001\n","NUM_LAYERS = 1\n","CLIP=5"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100\n","1773043\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"mhIJlbCZrekU","colab":{}},"cell_type":"code","source":["# --------------------- Tensorflow part ---------------------------------------------------\n","\n","def create_tensorflow_model(vocab_size, embedding_size, hidden_layer_dim):\n","    print(\"Creating TENSORFLOW model\")\n","     \n","    # Inputs have (batch_size, timesteps) shape.\n","    X = tf.placeholder(dtype=tf.int32,shape=[None,None,14],name='input_x')   \n","    # Labels have (batch_size,) shape.\n","    labels = tf.placeholder(dtype=tf.int32,shape=[None,None],name='input_y')\n","    # dropout_keep_prob is a scalar.\n","    dropout_keep_prob=tf.placeholder(dtype=tf.float32,name='dropout_keep_prob')\n","    # Calculate sequence lengths to mask out the paddings later on.\n","    seq_length = tf.reduce_sum(tf.cast( tf.not_equal(X[:,:,2], tf.ones_like(X[:,:,2]) * PAD_ID), tf.int32), 1)\n","        \n","    with tf.variable_scope('embeddings', reuse=tf.AUTO_REUSE):\n","        embedding_matrix = tf.Variable(word_embeddings, dtype=tf.float32, name='embedding')\n","        #embedding_matrix = tf.get_variable(\"embeddings\", shape=[vocab_size, embedding_size])\n","        embeddings = tf.nn.embedding_lookup(embedding_matrix, X)\n","        embeddings = tf.reshape(embeddings,[tf.size(X[:,1,1]),-1,14*embedding_size])\n","    \n","    # embeddings shape (batch size, sentence length with padding, 1400)\n","    embeddings=tf.nn.dropout(tf.cast(embeddings,tf.float32),dropout_keep_prob)\n","    \n","    with tf.variable_scope('rnn_cell', reuse=tf.AUTO_REUSE):\n","            print ('rnn_cell is lstm')\n","            def lstm_cell():\n","                return tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(hidden_layer_dim), output_keep_prob=dropout_keep_prob)\n","        \n","            def gru_cell():\n","                return tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.GRUCell(hidden_layer_dim), output_keep_prob=dropout_keep_prob)\n","        \n","            stacked_fw_lstm = tf.nn.rnn_cell.MultiRNNCell(\n","                [gru_cell() for _ in range(NUM_LAYERS)])\n","            \n","            stacked_bw_lstm = tf.nn.rnn_cell.MultiRNNCell(\n","                [lstm_cell() for _ in range(NUM_LAYERS)])\n","        \n","    with tf.variable_scope('rnn', reuse=tf.AUTO_REUSE):                        \n","            (forward_output,backword_output),_=tf.nn.bidirectional_dynamic_rnn(\n","                cell_fw=stacked_fw_lstm,\n","                cell_bw=stacked_bw_lstm,\n","                inputs=embeddings,\n","                sequence_length=seq_length,\n","                dtype=tf.float32\n","            )\n","            outputBidirection=tf.concat([forward_output,backword_output],axis=2)\n","            print ('outputBidirection is ok')    \n","                        \n","    print ('Loss Starts ....')\n","    with tf.variable_scope('loss', reuse=tf.AUTO_REUSE):\n","        output=layers.fully_connected(\n","            inputs=outputBidirection,\n","            num_outputs=NUM_CLASSES,\n","            activation_fn=None            \n","            )\n","        print ('output is ok ....')\n","        #crf\n","        log_likelihood, transition_params = crf.crf_log_likelihood(\n","            output, labels, seq_length)\n","        print ('crf_log_likelihood is ok ....')\n","        \n","        loss = tf.reduce_mean(-log_likelihood)\n","        print ('loss crf_log_likelihood is ok ....')\n","    \n","    print ('train-op Starts ....')\n","    with tf.variable_scope('train_op', reuse=tf.AUTO_REUSE):\n","        optimizer=tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n","        #optimizer=tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE, use_locking=False, name='GradientDescent') \n","        print ('optimizer is ok ....')\n","    \n","        tvars=tf.trainable_variables()\n","        print ('tvars is ok ....')\n","    \n","        l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in tvars if v.get_shape().ndims > 1])\n","        print ('l2_loss is ok ....')\n","        \n","        loss=loss+L2_REGU_LAMBDA*l2_loss\n","        print ('loss L2 is ok ....')\n","        \n","        grads,_=tf.clip_by_global_norm(tf.gradients(loss,tvars),CLIP)\n","        print ('grads is ok ....')\n","        \n","        train_op=optimizer.apply_gradients(zip(grads,tvars))\n","        print ('train_op apply_gradients is ok ....')\n","               \n","    return X, labels, output, train_op, dropout_keep_prob, loss, transition_params, seq_length\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1556118229578,"user_tz":-120,"elapsed":6357,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"id":"ORMyR5JN8FOv","outputId":"0fdb87b5-bb35-4fbb-d24f-dc132000c8db","colab":{"base_uri":"https://localhost:8080/","height":688}},"cell_type":"code","source":["# create tensorflow model\n","X, labels, output, train_op, dropout_keep_prob, loss, transition_params, seq_length = create_tensorflow_model(VOCAB_SIZE, WORD_EMBEDDING_DIM, HIDDEN_LAYER_DIM)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Creating TENSORFLOW model\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From <ipython-input-17-84ea786d31d9>:21: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","rnn_cell is lstm\n","WARNING:tensorflow:From <ipython-input-17-84ea786d31d9>:26: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-17-84ea786d31d9>:33: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-17-84ea786d31d9>:44: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","outputBidirection is ok\n","Loss Starts ....\n","output is ok ....\n","crf_log_likelihood is ok ....\n","loss crf_log_likelihood is ok ....\n","train-op Starts ....\n","optimizer is ok ....\n","tvars is ok ....\n","l2_loss is ok ....\n","loss L2 is ok ....\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["grads is ok ....\n","train_op apply_gradients is ok ....\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"nr7qsWJX5FE-"},"cell_type":"markdown","source":["***TensorFlow Model Training Section***\n","\n","*   Batch Base Padding Is Performed\n","* \n","\n"]},{"metadata":{"colab_type":"code","id":"3nZNAAVDb9Ya","colab":{}},"cell_type":"code","source":["# SUBSET_MODEL_ADD = root_path+'best_model_path68.5505176271315/model.ckpt'\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1555886941898,"user_tz":-120,"elapsed":95659,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"id":"5I0n7w2XnKX4","outputId":"a5459757-99a2-4cd4-db66-d245fb79c9df","colab":{"base_uri":"https://localhost:8080/","height":18088}},"cell_type":"code","source":["# Run tensorflow model\n","saver = tf.train.Saver()\n","\n","with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess: \n","    # I couln't use tensorboard because it causes my colab session to crash for big datasets.\n","    #train_writer = tf.summary.FileWriter(root_path+'logging/tensorflow_model', sess.graph)\n","\n","    sess.run(tf.global_variables_initializer())             \n","    print ('start session is ok ....')\n","    \n","    for epoch in range(NUM_EPOCHS):        \n","        #train\n","        train_loss=[]    \n","        for i in range(0, len(train_x), BATCH_SIZE):\n","            # slice dataset for padding\n","            batch_x = train_x[slice(i, i + BATCH_SIZE)]\n","            batch_y = train_y[slice(i, i + BATCH_SIZE)]\n","            batch_x = padding3(batch_x, PAD_ID)\n","            batch_y = padding(batch_y, PAD_ID)\n","            \n","            # runnig training session ang getting train loss for every batch and append in epoch loss\n","            _,loss_other=sess.run(\n","                [train_op, loss], feed_dict = { X:batch_x, labels:batch_y, dropout_keep_prob:0.3 })\n","            \n","            train_loss.append(loss_other)            \n","           # print ('Train batch %d loss %f' % (i, loss_other))\n","        train_loss=np.mean(train_loss,dtype=float)                \n","        print ('Train Epoch %d loss %f' % (epoch+1, train_loss))        \n","        print('--------------------------------') \n","        \n","                                       \n","        #Dev\n","        dev_loss=[]\n","        dev_pred=[]\n","        dev_hit_all=0\n","        dev_all_char=0        \n","        for i in range(0, len(dev_x), BATCH_SIZE):\n","            batch_x = dev_x[slice(i, i + BATCH_SIZE)]\n","            batch_y = dev_y[slice(i, i + BATCH_SIZE)]\n","            batch_x = padding3(batch_x, PAD_ID)\n","            batch_y = padding(batch_y, PAD_ID)\n","            \n","            # lengths is length of every sentence(number of words), unary_scores is sentences with padding and\n","            # transition_param_dev is probabilities matrix\n","            loss_other,lengths,unary_scores,transition_param_dev=sess.run(\n","                [loss,seq_length,output, transition_params], feed_dict = { X:batch_x, labels:batch_y, dropout_keep_prob:1.0 })\n","            \n","            # predict is every batches sentences prediction and for preventing any empty line causing error in prediction\n","            # I use lenghs>0 condition and then append prediction to epoch prediction\n","            predict=[]\n","            for unary_score,length in zip(unary_scores,lengths):    \n","                if length > 0:\n","                    viterbi_sequence, _= tf.contrib.crf.viterbi_decode(unary_score[:length],transition_param_dev)                             \n","                    predict.append(viterbi_sequence)\n","                else:\n","                    predict.append(\"\")\n","            \n","            dev_pred+=predict\n","            \n","            # number_of_batch_hits gave us all charachters of the batch and true predictions and we append\n","            #them to epoch hit and epoch all chars\n","            dev_batch_hit,dev_batch_char = number_of_batch_hits(predict,dev_y[slice(i, i + BATCH_SIZE)])            \n","            print('dev batch %d loss %f dev_batch_hit:%d dev_batch_char:%d batch_accuracy:%f' % (i, loss_other, dev_batch_hit, dev_batch_char,(dev_batch_hit/dev_batch_char)*100 ))\n","            dev_loss.append(loss_other)            \n","            dev_hit_all+=dev_batch_hit\n","            dev_all_char+=dev_batch_char\n","                \n","        dev_loss=np.mean(dev_loss,dtype=float)\n","        dev_acc = (dev_hit_all/dev_all_char)*100\n","        print('Valid Epoch %d loss %f' % (epoch+1,dev_loss))        \n","        print('dev_hit_all:%d dev_all_char:%d accuracy:%f' % (dev_hit_all,dev_all_char,dev_acc ))\n","        print('--------------------------------')  \n","        \n","        #add_summary(train_writer, \"epoch_dev_loss\", dev_loss, epoch+1)\n","        #add_summary(train_writer, \"epoch_dev_acc\", dev_acc, epoch+1)\n","        \n","        # Test        \n","        test_hit_all=0\n","        test_all_char=0        \n","        test_pred = []\n","        for i in range(0, len(test_x), BATCH_SIZE):\n","            batch_x = test_x[slice(i, i + BATCH_SIZE)]\n","            batch_y = test_y[slice(i, i + BATCH_SIZE)]\n","            batch_x = padding3(batch_x, PAD_ID)\n","            batch_y = padding(batch_y,PAD_ID)\n","            \n","            lengths,unary_scores,transition_param_test = sess.run(\n","                [seq_length,output,transition_params], feed_dict = {X:batch_x, dropout_keep_prob:1.0})\n","            predict=[]\n","            for unary_score,length in zip(unary_scores,lengths):\n","                if length > 0 :\n","                    viterbi_sequence, _=crf.viterbi_decode(unary_score[:length],transition_param_test)\n","                    predict.append(viterbi_sequence)\n","                else:\n","                    predict.append(\"\")\n","                #print('sentence length : %d' % (length))\n","                #print(viterbi_sequence)\n","            test_pred += predict \n","            \n","            test_batch_hit,test_batch_char = number_of_batch_hits(predict, test_y[slice(i, i + BATCH_SIZE)])            \n","            print('test batch %d test_batch_hit:%d test_batch_char:%d batch_accuracy:%f' % (i, test_batch_hit, test_batch_char,(test_batch_hit/test_batch_char)*100 ))\n","            test_hit_all+=test_batch_hit\n","            test_all_char+=test_batch_char\n","            \n","        test_acc = (test_hit_all/test_all_char)*100\n","        print('test_hit:%d test_all_char:%d accuracy:%f' % (test_hit_all,test_all_char,test_acc ))\n","        print(\"--------------------------------------------\")\n","        \n","        # I'm Saving my model in every epoch for selecting best one in case of overfitting in further epochs\n","        #if test_acc > 96.20:\n","        print(\"accuracy is: %f\" % (test_acc))\n","        save_path = saver.save(sess, root_path+'best_model_path{}/model.ckpt'.format(test_acc))\n","        print(\"Model saved in path: %s\" % save_path)            \n","        #add_summary(train_writer, \"epoch_test_acc\", test_acc, epoch+1)\n","        \n","    # Save the variables to disk.\n","#     save_path = saver.save(sess, root_path+'best_model_path/model.ckpt')\n","#     print(\"Model saved in path: %s\" % save_path)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["start session is ok ....\n","Train Epoch 1 loss 20.349687\n","--------------------------------\n","dev batch 0 loss 4.178298 dev_batch_hit:663 dev_batch_char:679 batch_accuracy:97.643594\n","dev batch 16 loss 3.464298 dev_batch_hit:681 dev_batch_char:711 batch_accuracy:95.780591\n","dev batch 32 loss 5.076274 dev_batch_hit:861 dev_batch_char:895 batch_accuracy:96.201117\n","dev batch 48 loss 2.474782 dev_batch_hit:802 dev_batch_char:807 batch_accuracy:99.380421\n","dev batch 64 loss 3.413298 dev_batch_hit:744 dev_batch_char:760 batch_accuracy:97.894737\n","dev batch 80 loss 3.945877 dev_batch_hit:900 dev_batch_char:927 batch_accuracy:97.087379\n","dev batch 96 loss 3.981677 dev_batch_hit:749 dev_batch_char:774 batch_accuracy:96.770026\n","dev batch 112 loss 3.372197 dev_batch_hit:671 dev_batch_char:684 batch_accuracy:98.099415\n","dev batch 128 loss 3.329278 dev_batch_hit:683 dev_batch_char:699 batch_accuracy:97.711016\n","dev batch 144 loss 2.954602 dev_batch_hit:814 dev_batch_char:826 batch_accuracy:98.547215\n","dev batch 160 loss 2.536886 dev_batch_hit:556 dev_batch_char:562 batch_accuracy:98.932384\n","dev batch 176 loss 5.278996 dev_batch_hit:854 dev_batch_char:894 batch_accuracy:95.525727\n","dev batch 192 loss 3.344222 dev_batch_hit:697 dev_batch_char:712 batch_accuracy:97.893258\n","dev batch 208 loss 3.367625 dev_batch_hit:621 dev_batch_char:642 batch_accuracy:96.728972\n","dev batch 224 loss 3.623457 dev_batch_hit:843 dev_batch_char:855 batch_accuracy:98.596491\n","dev batch 240 loss 4.805037 dev_batch_hit:740 dev_batch_char:777 batch_accuracy:95.238095\n","dev batch 256 loss 2.756085 dev_batch_hit:798 dev_batch_char:808 batch_accuracy:98.762376\n","dev batch 272 loss 3.054841 dev_batch_hit:609 dev_batch_char:630 batch_accuracy:96.666667\n","dev batch 288 loss 2.202050 dev_batch_hit:743 dev_batch_char:749 batch_accuracy:99.198932\n","dev batch 304 loss 2.760376 dev_batch_hit:735 dev_batch_char:745 batch_accuracy:98.657718\n","dev batch 320 loss 2.988961 dev_batch_hit:813 dev_batch_char:826 batch_accuracy:98.426150\n","dev batch 336 loss 3.342788 dev_batch_hit:848 dev_batch_char:869 batch_accuracy:97.583429\n","dev batch 352 loss 5.704389 dev_batch_hit:929 dev_batch_char:975 batch_accuracy:95.282051\n","dev batch 368 loss 3.138101 dev_batch_hit:743 dev_batch_char:765 batch_accuracy:97.124183\n","dev batch 384 loss 2.508916 dev_batch_hit:719 dev_batch_char:725 batch_accuracy:99.172414\n","dev batch 400 loss 2.230905 dev_batch_hit:754 dev_batch_char:756 batch_accuracy:99.735450\n","dev batch 416 loss 3.611014 dev_batch_hit:830 dev_batch_char:850 batch_accuracy:97.647059\n","dev batch 432 loss 4.152816 dev_batch_hit:673 dev_batch_char:700 batch_accuracy:96.142857\n","dev batch 448 loss 12.552472 dev_batch_hit:839 dev_batch_char:915 batch_accuracy:91.693989\n","dev batch 464 loss 2.641127 dev_batch_hit:768 dev_batch_char:783 batch_accuracy:98.084291\n","dev batch 480 loss 3.928994 dev_batch_hit:782 dev_batch_char:803 batch_accuracy:97.384807\n","dev batch 496 loss 2.272583 dev_batch_hit:785 dev_batch_char:790 batch_accuracy:99.367089\n","dev batch 512 loss 3.019087 dev_batch_hit:644 dev_batch_char:652 batch_accuracy:98.773006\n","dev batch 528 loss 3.242196 dev_batch_hit:634 dev_batch_char:646 batch_accuracy:98.142415\n","dev batch 544 loss 3.545511 dev_batch_hit:794 dev_batch_char:813 batch_accuracy:97.662977\n","dev batch 560 loss 2.669701 dev_batch_hit:533 dev_batch_char:542 batch_accuracy:98.339483\n","dev batch 576 loss 3.739063 dev_batch_hit:657 dev_batch_char:669 batch_accuracy:98.206278\n","dev batch 592 loss 3.624434 dev_batch_hit:879 dev_batch_char:895 batch_accuracy:98.212291\n","dev batch 608 loss 2.215332 dev_batch_hit:653 dev_batch_char:658 batch_accuracy:99.240122\n","dev batch 624 loss 2.824294 dev_batch_hit:636 dev_batch_char:645 batch_accuracy:98.604651\n","dev batch 640 loss 2.196377 dev_batch_hit:597 dev_batch_char:600 batch_accuracy:99.500000\n","dev batch 656 loss 2.499387 dev_batch_hit:672 dev_batch_char:684 batch_accuracy:98.245614\n","dev batch 672 loss 2.353069 dev_batch_hit:724 dev_batch_char:730 batch_accuracy:99.178082\n","dev batch 688 loss 2.780697 dev_batch_hit:702 dev_batch_char:712 batch_accuracy:98.595506\n","dev batch 704 loss 2.172421 dev_batch_hit:614 dev_batch_char:619 batch_accuracy:99.192246\n","dev batch 720 loss 2.417065 dev_batch_hit:763 dev_batch_char:773 batch_accuracy:98.706339\n","dev batch 736 loss 3.381559 dev_batch_hit:654 dev_batch_char:669 batch_accuracy:97.757848\n","dev batch 752 loss 4.581374 dev_batch_hit:722 dev_batch_char:750 batch_accuracy:96.266667\n","dev batch 768 loss 4.245857 dev_batch_hit:772 dev_batch_char:789 batch_accuracy:97.845374\n","dev batch 784 loss 3.633815 dev_batch_hit:719 dev_batch_char:733 batch_accuracy:98.090041\n","dev batch 800 loss 2.430255 dev_batch_hit:627 dev_batch_char:636 batch_accuracy:98.584906\n","dev batch 816 loss 3.778888 dev_batch_hit:663 dev_batch_char:687 batch_accuracy:96.506550\n","dev batch 832 loss 3.164701 dev_batch_hit:752 dev_batch_char:765 batch_accuracy:98.300654\n","dev batch 848 loss 3.257945 dev_batch_hit:570 dev_batch_char:586 batch_accuracy:97.269625\n","dev batch 864 loss 2.854030 dev_batch_hit:712 dev_batch_char:723 batch_accuracy:98.478562\n","dev batch 880 loss 4.509782 dev_batch_hit:713 dev_batch_char:731 batch_accuracy:97.537620\n","dev batch 896 loss 3.038804 dev_batch_hit:662 dev_batch_char:674 batch_accuracy:98.219585\n","dev batch 912 loss 3.540883 dev_batch_hit:708 dev_batch_char:735 batch_accuracy:96.326531\n","dev batch 928 loss 3.188967 dev_batch_hit:686 dev_batch_char:698 batch_accuracy:98.280802\n","dev batch 944 loss 2.741745 dev_batch_hit:899 dev_batch_char:907 batch_accuracy:99.117971\n","dev batch 960 loss 2.176280 dev_batch_hit:906 dev_batch_char:910 batch_accuracy:99.560440\n","dev batch 976 loss 5.116335 dev_batch_hit:661 dev_batch_char:693 batch_accuracy:95.382395\n","dev batch 992 loss 3.407155 dev_batch_hit:857 dev_batch_char:870 batch_accuracy:98.505747\n","dev batch 1008 loss 3.097700 dev_batch_hit:741 dev_batch_char:754 batch_accuracy:98.275862\n","dev batch 1024 loss 4.142202 dev_batch_hit:825 dev_batch_char:845 batch_accuracy:97.633136\n","dev batch 1040 loss 2.755690 dev_batch_hit:770 dev_batch_char:784 batch_accuracy:98.214286\n","dev batch 1056 loss 4.209551 dev_batch_hit:889 dev_batch_char:923 batch_accuracy:96.316360\n","dev batch 1072 loss 2.169420 dev_batch_hit:752 dev_batch_char:756 batch_accuracy:99.470899\n","dev batch 1088 loss 3.105954 dev_batch_hit:714 dev_batch_char:729 batch_accuracy:97.942387\n","dev batch 1104 loss 2.930782 dev_batch_hit:605 dev_batch_char:619 batch_accuracy:97.738288\n","dev batch 1120 loss 3.655468 dev_batch_hit:845 dev_batch_char:865 batch_accuracy:97.687861\n","dev batch 1136 loss 3.114625 dev_batch_hit:682 dev_batch_char:694 batch_accuracy:98.270893\n","dev batch 1152 loss 2.818615 dev_batch_hit:644 dev_batch_char:651 batch_accuracy:98.924731\n","dev batch 1168 loss 4.888762 dev_batch_hit:540 dev_batch_char:562 batch_accuracy:96.085409\n","dev batch 1184 loss 2.951130 dev_batch_hit:751 dev_batch_char:761 batch_accuracy:98.685940\n","dev batch 1200 loss 3.101649 dev_batch_hit:656 dev_batch_char:671 batch_accuracy:97.764531\n","dev batch 1216 loss 2.021255 dev_batch_hit:628 dev_batch_char:630 batch_accuracy:99.682540\n","dev batch 1232 loss 3.462503 dev_batch_hit:643 dev_batch_char:655 batch_accuracy:98.167939\n","dev batch 1248 loss 3.052417 dev_batch_hit:604 dev_batch_char:616 batch_accuracy:98.051948\n","dev batch 1264 loss 3.155001 dev_batch_hit:775 dev_batch_char:791 batch_accuracy:97.977244\n","dev batch 1280 loss 4.864190 dev_batch_hit:863 dev_batch_char:893 batch_accuracy:96.640538\n","dev batch 1296 loss 3.411994 dev_batch_hit:798 dev_batch_char:815 batch_accuracy:97.914110\n","dev batch 1312 loss 2.940459 dev_batch_hit:645 dev_batch_char:657 batch_accuracy:98.173516\n","dev batch 1328 loss 4.254794 dev_batch_hit:957 dev_batch_char:981 batch_accuracy:97.553517\n","dev batch 1344 loss 2.819555 dev_batch_hit:876 dev_batch_char:886 batch_accuracy:98.871332\n","dev batch 1360 loss 3.526856 dev_batch_hit:777 dev_batch_char:799 batch_accuracy:97.246558\n","dev batch 1376 loss 2.637091 dev_batch_hit:803 dev_batch_char:807 batch_accuracy:99.504337\n","dev batch 1392 loss 2.898698 dev_batch_hit:788 dev_batch_char:800 batch_accuracy:98.500000\n","dev batch 1408 loss 4.232544 dev_batch_hit:796 dev_batch_char:816 batch_accuracy:97.549020\n","dev batch 1424 loss 3.847344 dev_batch_hit:715 dev_batch_char:739 batch_accuracy:96.752368\n","dev batch 1440 loss 4.068974 dev_batch_hit:834 dev_batch_char:852 batch_accuracy:97.887324\n","dev batch 1456 loss 3.379407 dev_batch_hit:713 dev_batch_char:735 batch_accuracy:97.006803\n","dev batch 1472 loss 3.696218 dev_batch_hit:743 dev_batch_char:759 batch_accuracy:97.891963\n","dev batch 1488 loss 3.413907 dev_batch_hit:839 dev_batch_char:850 batch_accuracy:98.705882\n","dev batch 1504 loss 2.357775 dev_batch_hit:604 dev_batch_char:611 batch_accuracy:98.854337\n","dev batch 1520 loss 3.927512 dev_batch_hit:616 dev_batch_char:633 batch_accuracy:97.314376\n","dev batch 1536 loss 3.516186 dev_batch_hit:857 dev_batch_char:872 batch_accuracy:98.279817\n","dev batch 1552 loss 3.197935 dev_batch_hit:840 dev_batch_char:860 batch_accuracy:97.674419\n","dev batch 1568 loss 3.161479 dev_batch_hit:702 dev_batch_char:718 batch_accuracy:97.771588\n","dev batch 1584 loss 3.294826 dev_batch_hit:695 dev_batch_char:716 batch_accuracy:97.067039\n","dev batch 1600 loss 3.165546 dev_batch_hit:745 dev_batch_char:755 batch_accuracy:98.675497\n","dev batch 1616 loss 2.245296 dev_batch_hit:672 dev_batch_char:678 batch_accuracy:99.115044\n","dev batch 1632 loss 3.820547 dev_batch_hit:870 dev_batch_char:888 batch_accuracy:97.972973\n","dev batch 1648 loss 3.537761 dev_batch_hit:738 dev_batch_char:756 batch_accuracy:97.619048\n","dev batch 1664 loss 4.374540 dev_batch_hit:741 dev_batch_char:765 batch_accuracy:96.862745\n","dev batch 1680 loss 2.697710 dev_batch_hit:837 dev_batch_char:850 batch_accuracy:98.470588\n","dev batch 1696 loss 2.527571 dev_batch_hit:664 dev_batch_char:673 batch_accuracy:98.662704\n","dev batch 1712 loss 3.896443 dev_batch_hit:673 dev_batch_char:685 batch_accuracy:98.248175\n","dev batch 1728 loss 3.478466 dev_batch_hit:861 dev_batch_char:881 batch_accuracy:97.729852\n","dev batch 1744 loss 3.505398 dev_batch_hit:650 dev_batch_char:666 batch_accuracy:97.597598\n","dev batch 1760 loss 3.463668 dev_batch_hit:822 dev_batch_char:842 batch_accuracy:97.624703\n","dev batch 1776 loss 2.445047 dev_batch_hit:723 dev_batch_char:732 batch_accuracy:98.770492\n","dev batch 1792 loss 4.101063 dev_batch_hit:895 dev_batch_char:934 batch_accuracy:95.824411\n","dev batch 1808 loss 3.694000 dev_batch_hit:810 dev_batch_char:826 batch_accuracy:98.062954\n","dev batch 1824 loss 3.649613 dev_batch_hit:831 dev_batch_char:843 batch_accuracy:98.576512\n","dev batch 1840 loss 2.628043 dev_batch_hit:730 dev_batch_char:741 batch_accuracy:98.515520\n","dev batch 1856 loss 4.262733 dev_batch_hit:733 dev_batch_char:757 batch_accuracy:96.829590\n","dev batch 1872 loss 3.865387 dev_batch_hit:726 dev_batch_char:745 batch_accuracy:97.449664\n","dev batch 1888 loss 3.047836 dev_batch_hit:615 dev_batch_char:631 batch_accuracy:97.464342\n","dev batch 1904 loss 2.964150 dev_batch_hit:712 dev_batch_char:725 batch_accuracy:98.206897\n","dev batch 1920 loss 2.941664 dev_batch_hit:612 dev_batch_char:620 batch_accuracy:98.709677\n","dev batch 1936 loss 4.240714 dev_batch_hit:626 dev_batch_char:657 batch_accuracy:95.281583\n","dev batch 1952 loss 3.055311 dev_batch_hit:650 dev_batch_char:665 batch_accuracy:97.744361\n","dev batch 1968 loss 4.074237 dev_batch_hit:843 dev_batch_char:860 batch_accuracy:98.023256\n","dev batch 1984 loss 3.254852 dev_batch_hit:723 dev_batch_char:735 batch_accuracy:98.367347\n","dev batch 2000 loss 3.577837 dev_batch_hit:644 dev_batch_char:663 batch_accuracy:97.134238\n","dev batch 2016 loss 3.616585 dev_batch_hit:663 dev_batch_char:681 batch_accuracy:97.356828\n","dev batch 2032 loss 2.106765 dev_batch_hit:807 dev_batch_char:811 batch_accuracy:99.506782\n","dev batch 2048 loss 2.897102 dev_batch_hit:719 dev_batch_char:732 batch_accuracy:98.224044\n","dev batch 2064 loss 2.463786 dev_batch_hit:599 dev_batch_char:609 batch_accuracy:98.357964\n","dev batch 2080 loss 2.945566 dev_batch_hit:686 dev_batch_char:695 batch_accuracy:98.705036\n","dev batch 2096 loss 2.952084 dev_batch_hit:639 dev_batch_char:657 batch_accuracy:97.260274\n","dev batch 2112 loss 2.400124 dev_batch_hit:753 dev_batch_char:762 batch_accuracy:98.818898\n","dev batch 2128 loss 3.531922 dev_batch_hit:869 dev_batch_char:889 batch_accuracy:97.750281\n","dev batch 2144 loss 2.701138 dev_batch_hit:658 dev_batch_char:670 batch_accuracy:98.208955\n","dev batch 2160 loss 2.883726 dev_batch_hit:820 dev_batch_char:830 batch_accuracy:98.795181\n","dev batch 2176 loss 3.707606 dev_batch_hit:684 dev_batch_char:703 batch_accuracy:97.297297\n","dev batch 2192 loss 2.247114 dev_batch_hit:688 dev_batch_char:694 batch_accuracy:99.135447\n","dev batch 2208 loss 3.094557 dev_batch_hit:843 dev_batch_char:861 batch_accuracy:97.909408\n","dev batch 2224 loss 2.751286 dev_batch_hit:693 dev_batch_char:700 batch_accuracy:99.000000\n","dev batch 2240 loss 2.770565 dev_batch_hit:696 dev_batch_char:709 batch_accuracy:98.166432\n","dev batch 2256 loss 2.542454 dev_batch_hit:686 dev_batch_char:695 batch_accuracy:98.705036\n","dev batch 2272 loss 4.386034 dev_batch_hit:884 dev_batch_char:911 batch_accuracy:97.036224\n","dev batch 2288 loss 2.898030 dev_batch_hit:647 dev_batch_char:653 batch_accuracy:99.081164\n","dev batch 2304 loss 3.737919 dev_batch_hit:842 dev_batch_char:867 batch_accuracy:97.116494\n","dev batch 2320 loss 2.649565 dev_batch_hit:731 dev_batch_char:739 batch_accuracy:98.917456\n","dev batch 2336 loss 2.240138 dev_batch_hit:620 dev_batch_char:626 batch_accuracy:99.041534\n","dev batch 2352 loss 2.370377 dev_batch_hit:596 dev_batch_char:604 batch_accuracy:98.675497\n","dev batch 2368 loss 2.284175 dev_batch_hit:741 dev_batch_char:746 batch_accuracy:99.329759\n","dev batch 2384 loss 2.662892 dev_batch_hit:682 dev_batch_char:695 batch_accuracy:98.129496\n","dev batch 2400 loss 2.523989 dev_batch_hit:698 dev_batch_char:705 batch_accuracy:99.007092\n","dev batch 2416 loss 2.926481 dev_batch_hit:748 dev_batch_char:760 batch_accuracy:98.421053\n","dev batch 2432 loss 3.086875 dev_batch_hit:624 dev_batch_char:637 batch_accuracy:97.959184\n","dev batch 2448 loss 4.291289 dev_batch_hit:926 dev_batch_char:952 batch_accuracy:97.268908\n","dev batch 2464 loss 3.512394 dev_batch_hit:734 dev_batch_char:748 batch_accuracy:98.128342\n","dev batch 2480 loss 3.528581 dev_batch_hit:657 dev_batch_char:682 batch_accuracy:96.334311\n","dev batch 2496 loss 4.149328 dev_batch_hit:864 dev_batch_char:894 batch_accuracy:96.644295\n","dev batch 2512 loss 3.233033 dev_batch_hit:748 dev_batch_char:761 batch_accuracy:98.291721\n","dev batch 2528 loss 3.276923 dev_batch_hit:872 dev_batch_char:881 batch_accuracy:98.978434\n","dev batch 2544 loss 5.187105 dev_batch_hit:828 dev_batch_char:861 batch_accuracy:96.167247\n","dev batch 2560 loss 3.059342 dev_batch_hit:459 dev_batch_char:472 batch_accuracy:97.245763\n","dev batch 2576 loss 2.604851 dev_batch_hit:823 dev_batch_char:831 batch_accuracy:99.037304\n","dev batch 2592 loss 3.492780 dev_batch_hit:664 dev_batch_char:682 batch_accuracy:97.360704\n","dev batch 2608 loss 3.680962 dev_batch_hit:792 dev_batch_char:805 batch_accuracy:98.385093\n","dev batch 2624 loss 3.938650 dev_batch_hit:722 dev_batch_char:734 batch_accuracy:98.365123\n","dev batch 2640 loss 3.565866 dev_batch_hit:696 dev_batch_char:710 batch_accuracy:98.028169\n","dev batch 2656 loss 2.435448 dev_batch_hit:741 dev_batch_char:749 batch_accuracy:98.931909\n","dev batch 2672 loss 3.122220 dev_batch_hit:968 dev_batch_char:979 batch_accuracy:98.876404\n","dev batch 2688 loss 2.376869 dev_batch_hit:621 dev_batch_char:631 batch_accuracy:98.415214\n","dev batch 2704 loss 2.397890 dev_batch_hit:714 dev_batch_char:720 batch_accuracy:99.166667\n","dev batch 2720 loss 2.833837 dev_batch_hit:647 dev_batch_char:668 batch_accuracy:96.856287\n","dev batch 2736 loss 2.053797 dev_batch_hit:528 dev_batch_char:530 batch_accuracy:99.622642\n","dev batch 2752 loss 2.776012 dev_batch_hit:702 dev_batch_char:716 batch_accuracy:98.044693\n","dev batch 2768 loss 3.231992 dev_batch_hit:755 dev_batch_char:769 batch_accuracy:98.179454\n","dev batch 2784 loss 3.944377 dev_batch_hit:773 dev_batch_char:800 batch_accuracy:96.625000\n","dev batch 2800 loss 2.360844 dev_batch_hit:877 dev_batch_char:879 batch_accuracy:99.772469\n","dev batch 2816 loss 3.072091 dev_batch_hit:697 dev_batch_char:720 batch_accuracy:96.805556\n","dev batch 2832 loss 2.861852 dev_batch_hit:852 dev_batch_char:869 batch_accuracy:98.043728\n","dev batch 2848 loss 3.048849 dev_batch_hit:675 dev_batch_char:683 batch_accuracy:98.828697\n","dev batch 2864 loss 2.755016 dev_batch_hit:645 dev_batch_char:655 batch_accuracy:98.473282\n","dev batch 2880 loss 3.647187 dev_batch_hit:986 dev_batch_char:1006 batch_accuracy:98.011928\n","dev batch 2896 loss 2.450228 dev_batch_hit:657 dev_batch_char:670 batch_accuracy:98.059701\n","dev batch 2912 loss 2.901407 dev_batch_hit:716 dev_batch_char:728 batch_accuracy:98.351648\n","dev batch 2928 loss 3.179768 dev_batch_hit:646 dev_batch_char:671 batch_accuracy:96.274218\n","dev batch 2944 loss 2.364037 dev_batch_hit:752 dev_batch_char:758 batch_accuracy:99.208443\n","dev batch 2960 loss 2.573629 dev_batch_hit:540 dev_batch_char:548 batch_accuracy:98.540146\n","dev batch 2976 loss 2.842775 dev_batch_hit:708 dev_batch_char:721 batch_accuracy:98.196949\n","dev batch 2992 loss 4.239783 dev_batch_hit:769 dev_batch_char:807 batch_accuracy:95.291202\n","dev batch 3008 loss 4.095600 dev_batch_hit:786 dev_batch_char:807 batch_accuracy:97.397770\n","dev batch 3024 loss 3.031832 dev_batch_hit:859 dev_batch_char:872 batch_accuracy:98.509174\n","dev batch 3040 loss 3.190078 dev_batch_hit:583 dev_batch_char:595 batch_accuracy:97.983193\n","dev batch 3056 loss 3.636366 dev_batch_hit:645 dev_batch_char:670 batch_accuracy:96.268657\n","dev batch 3072 loss 3.034904 dev_batch_hit:665 dev_batch_char:674 batch_accuracy:98.664688\n","dev batch 3088 loss 3.236696 dev_batch_hit:565 dev_batch_char:583 batch_accuracy:96.912521\n","dev batch 3104 loss 2.700537 dev_batch_hit:768 dev_batch_char:783 batch_accuracy:98.084291\n","dev batch 3120 loss 2.768683 dev_batch_hit:976 dev_batch_char:985 batch_accuracy:99.086294\n","dev batch 3136 loss 3.005923 dev_batch_hit:769 dev_batch_char:779 batch_accuracy:98.716303\n","dev batch 3152 loss 4.073150 dev_batch_hit:674 dev_batch_char:692 batch_accuracy:97.398844\n","dev batch 3168 loss 2.483158 dev_batch_hit:621 dev_batch_char:628 batch_accuracy:98.885350\n","dev batch 3184 loss 2.798326 dev_batch_hit:842 dev_batch_char:850 batch_accuracy:99.058824\n","dev batch 3200 loss 2.714956 dev_batch_hit:743 dev_batch_char:749 batch_accuracy:99.198932\n","dev batch 3216 loss 4.831128 dev_batch_hit:908 dev_batch_char:929 batch_accuracy:97.739505\n","dev batch 3232 loss 2.666253 dev_batch_hit:590 dev_batch_char:598 batch_accuracy:98.662207\n","dev batch 3248 loss 3.033865 dev_batch_hit:687 dev_batch_char:702 batch_accuracy:97.863248\n","dev batch 3264 loss 3.450925 dev_batch_hit:715 dev_batch_char:733 batch_accuracy:97.544338\n","dev batch 3280 loss 2.379065 dev_batch_hit:748 dev_batch_char:759 batch_accuracy:98.550725\n","dev batch 3296 loss 2.687896 dev_batch_hit:583 dev_batch_char:587 batch_accuracy:99.318569\n","dev batch 3312 loss 3.108315 dev_batch_hit:787 dev_batch_char:812 batch_accuracy:96.921182\n","dev batch 3328 loss 6.161679 dev_batch_hit:764 dev_batch_char:795 batch_accuracy:96.100629\n","dev batch 3344 loss 3.019381 dev_batch_hit:758 dev_batch_char:770 batch_accuracy:98.441558\n","dev batch 3360 loss 5.548430 dev_batch_hit:774 dev_batch_char:804 batch_accuracy:96.268657\n","dev batch 3376 loss 3.314898 dev_batch_hit:703 dev_batch_char:721 batch_accuracy:97.503467\n","dev batch 3392 loss 3.470470 dev_batch_hit:770 dev_batch_char:791 batch_accuracy:97.345133\n","dev batch 3408 loss 3.958897 dev_batch_hit:661 dev_batch_char:680 batch_accuracy:97.205882\n","dev batch 3424 loss 3.164262 dev_batch_hit:904 dev_batch_char:919 batch_accuracy:98.367791\n","dev batch 3440 loss 2.370146 dev_batch_hit:563 dev_batch_char:571 batch_accuracy:98.598949\n","dev batch 3456 loss 3.319969 dev_batch_hit:879 dev_batch_char:898 batch_accuracy:97.884187\n","dev batch 3472 loss 3.962800 dev_batch_hit:856 dev_batch_char:880 batch_accuracy:97.272727\n","dev batch 3488 loss 4.225975 dev_batch_hit:566 dev_batch_char:587 batch_accuracy:96.422487\n","dev batch 3504 loss 4.420506 dev_batch_hit:853 dev_batch_char:874 batch_accuracy:97.597254\n","dev batch 3520 loss 2.370203 dev_batch_hit:580 dev_batch_char:589 batch_accuracy:98.471986\n","dev batch 3536 loss 2.216840 dev_batch_hit:631 dev_batch_char:635 batch_accuracy:99.370079\n","dev batch 3552 loss 2.984992 dev_batch_hit:594 dev_batch_char:604 batch_accuracy:98.344371\n","dev batch 3568 loss 2.900576 dev_batch_hit:835 dev_batch_char:843 batch_accuracy:99.051008\n","dev batch 3584 loss 4.326593 dev_batch_hit:841 dev_batch_char:860 batch_accuracy:97.790698\n","dev batch 3600 loss 2.924601 dev_batch_hit:728 dev_batch_char:736 batch_accuracy:98.913043\n","dev batch 3616 loss 2.097310 dev_batch_hit:773 dev_batch_char:777 batch_accuracy:99.485199\n","dev batch 3632 loss 3.048649 dev_batch_hit:651 dev_batch_char:662 batch_accuracy:98.338369\n","dev batch 3648 loss 2.854604 dev_batch_hit:777 dev_batch_char:788 batch_accuracy:98.604061\n","dev batch 3664 loss 2.584469 dev_batch_hit:708 dev_batch_char:719 batch_accuracy:98.470097\n","dev batch 3680 loss 2.355269 dev_batch_hit:700 dev_batch_char:708 batch_accuracy:98.870056\n","dev batch 3696 loss 2.843538 dev_batch_hit:882 dev_batch_char:892 batch_accuracy:98.878924\n","dev batch 3712 loss 2.321675 dev_batch_hit:642 dev_batch_char:648 batch_accuracy:99.074074\n","dev batch 3728 loss 2.885048 dev_batch_hit:740 dev_batch_char:751 batch_accuracy:98.535286\n","dev batch 3744 loss 2.675502 dev_batch_hit:635 dev_batch_char:647 batch_accuracy:98.145286\n","dev batch 3760 loss 2.640651 dev_batch_hit:720 dev_batch_char:733 batch_accuracy:98.226467\n","dev batch 3776 loss 3.341181 dev_batch_hit:780 dev_batch_char:800 batch_accuracy:97.500000\n","dev batch 3792 loss 2.494025 dev_batch_hit:572 dev_batch_char:578 batch_accuracy:98.961938\n","dev batch 3808 loss 2.142680 dev_batch_hit:555 dev_batch_char:557 batch_accuracy:99.640934\n","dev batch 3824 loss 2.401139 dev_batch_hit:795 dev_batch_char:801 batch_accuracy:99.250936\n","dev batch 3840 loss 3.530791 dev_batch_hit:888 dev_batch_char:909 batch_accuracy:97.689769\n","dev batch 3856 loss 2.969536 dev_batch_hit:742 dev_batch_char:752 batch_accuracy:98.670213\n","dev batch 3872 loss 3.488958 dev_batch_hit:677 dev_batch_char:696 batch_accuracy:97.270115\n","dev batch 3888 loss 3.274326 dev_batch_hit:1001 dev_batch_char:1014 batch_accuracy:98.717949\n","dev batch 3904 loss 4.121684 dev_batch_hit:762 dev_batch_char:780 batch_accuracy:97.692308\n","dev batch 3920 loss 2.387336 dev_batch_hit:615 dev_batch_char:624 batch_accuracy:98.557692\n","dev batch 3936 loss 3.536829 dev_batch_hit:640 dev_batch_char:655 batch_accuracy:97.709924\n","dev batch 3952 loss 2.733804 dev_batch_hit:773 dev_batch_char:785 batch_accuracy:98.471338\n","dev batch 3968 loss 3.297379 dev_batch_hit:900 dev_batch_char:913 batch_accuracy:98.576123\n","dev batch 3984 loss 3.358946 dev_batch_hit:851 dev_batch_char:871 batch_accuracy:97.703789\n","dev batch 4000 loss 2.855044 dev_batch_hit:822 dev_batch_char:836 batch_accuracy:98.325359\n","dev batch 4016 loss 3.191147 dev_batch_hit:744 dev_batch_char:757 batch_accuracy:98.282695\n","dev batch 4032 loss 4.709897 dev_batch_hit:821 dev_batch_char:842 batch_accuracy:97.505938\n","dev batch 4048 loss 2.635986 dev_batch_hit:665 dev_batch_char:677 batch_accuracy:98.227474\n","dev batch 4064 loss 2.487012 dev_batch_hit:799 dev_batch_char:803 batch_accuracy:99.501868\n","dev batch 4080 loss 3.805565 dev_batch_hit:650 dev_batch_char:673 batch_accuracy:96.582467\n","dev batch 4096 loss 2.513931 dev_batch_hit:719 dev_batch_char:728 batch_accuracy:98.763736\n","dev batch 4112 loss 3.827988 dev_batch_hit:819 dev_batch_char:840 batch_accuracy:97.500000\n","dev batch 4128 loss 2.924712 dev_batch_hit:977 dev_batch_char:987 batch_accuracy:98.986829\n","dev batch 4144 loss 3.685064 dev_batch_hit:651 dev_batch_char:666 batch_accuracy:97.747748\n","dev batch 4160 loss 2.830336 dev_batch_hit:560 dev_batch_char:569 batch_accuracy:98.418278\n","dev batch 4176 loss 2.383103 dev_batch_hit:802 dev_batch_char:807 batch_accuracy:99.380421\n","dev batch 4192 loss 3.182195 dev_batch_hit:789 dev_batch_char:797 batch_accuracy:98.996236\n","dev batch 4208 loss 2.737967 dev_batch_hit:675 dev_batch_char:683 batch_accuracy:98.828697\n","dev batch 4224 loss 2.253302 dev_batch_hit:717 dev_batch_char:723 batch_accuracy:99.170124\n","dev batch 4240 loss 3.618941 dev_batch_hit:746 dev_batch_char:759 batch_accuracy:98.287220\n","dev batch 4256 loss 3.856688 dev_batch_hit:710 dev_batch_char:737 batch_accuracy:96.336499\n","dev batch 4272 loss 2.057188 dev_batch_hit:1156 dev_batch_char:1161 batch_accuracy:99.569337\n","dev batch 4288 loss 3.666555 dev_batch_hit:622 dev_batch_char:641 batch_accuracy:97.035881\n","dev batch 4304 loss 3.097059 dev_batch_hit:815 dev_batch_char:831 batch_accuracy:98.074609\n","dev batch 4320 loss 2.709248 dev_batch_hit:642 dev_batch_char:651 batch_accuracy:98.617512\n","dev batch 4336 loss 1.859249 dev_batch_hit:447 dev_batch_char:447 batch_accuracy:100.000000\n","Valid Epoch 1 loss 3.243266\n","dev_hit_all:199674 dev_all_char:203715 accuracy:98.016346\n","--------------------------------\n","test batch 0 test_batch_hit:388 test_batch_char:400 batch_accuracy:97.000000\n","test batch 16 test_batch_hit:549 test_batch_char:554 batch_accuracy:99.097473\n","test batch 32 test_batch_hit:555 test_batch_char:573 batch_accuracy:96.858639\n","test batch 48 test_batch_hit:538 test_batch_char:550 batch_accuracy:97.818182\n","test batch 64 test_batch_hit:710 test_batch_char:716 batch_accuracy:99.162011\n","test batch 80 test_batch_hit:586 test_batch_char:617 batch_accuracy:94.975689\n","test batch 96 test_batch_hit:456 test_batch_char:492 batch_accuracy:92.682927\n","test batch 112 test_batch_hit:545 test_batch_char:592 batch_accuracy:92.060811\n","test batch 128 test_batch_hit:705 test_batch_char:726 batch_accuracy:97.107438\n","test batch 144 test_batch_hit:716 test_batch_char:735 batch_accuracy:97.414966\n","test batch 160 test_batch_hit:478 test_batch_char:511 batch_accuracy:93.542074\n","test batch 176 test_batch_hit:486 test_batch_char:490 batch_accuracy:99.183673\n","test batch 192 test_batch_hit:396 test_batch_char:412 batch_accuracy:96.116505\n","test batch 208 test_batch_hit:520 test_batch_char:532 batch_accuracy:97.744361\n","test batch 224 test_batch_hit:503 test_batch_char:510 batch_accuracy:98.627451\n","test batch 240 test_batch_hit:721 test_batch_char:729 batch_accuracy:98.902606\n","test batch 256 test_batch_hit:568 test_batch_char:574 batch_accuracy:98.954704\n","test batch 272 test_batch_hit:519 test_batch_char:537 batch_accuracy:96.648045\n","test batch 288 test_batch_hit:712 test_batch_char:728 batch_accuracy:97.802198\n","test batch 304 test_batch_hit:1121 test_batch_char:1137 batch_accuracy:98.592788\n","test batch 320 test_batch_hit:916 test_batch_char:928 batch_accuracy:98.706897\n","test batch 336 test_batch_hit:681 test_batch_char:702 batch_accuracy:97.008547\n","test batch 352 test_batch_hit:1052 test_batch_char:1068 batch_accuracy:98.501873\n","test batch 368 test_batch_hit:755 test_batch_char:775 batch_accuracy:97.419355\n","test batch 384 test_batch_hit:865 test_batch_char:910 batch_accuracy:95.054945\n","test batch 400 test_batch_hit:569 test_batch_char:575 batch_accuracy:98.956522\n","test batch 416 test_batch_hit:751 test_batch_char:832 batch_accuracy:90.264423\n","test batch 432 test_batch_hit:853 test_batch_char:895 batch_accuracy:95.307263\n","test batch 448 test_batch_hit:708 test_batch_char:720 batch_accuracy:98.333333\n","test batch 464 test_batch_hit:493 test_batch_char:500 batch_accuracy:98.600000\n","test batch 480 test_batch_hit:815 test_batch_char:821 batch_accuracy:99.269184\n","test batch 496 test_batch_hit:575 test_batch_char:598 batch_accuracy:96.153846\n","test batch 512 test_batch_hit:974 test_batch_char:988 batch_accuracy:98.582996\n","test batch 528 test_batch_hit:495 test_batch_char:503 batch_accuracy:98.409543\n","test batch 544 test_batch_hit:669 test_batch_char:699 batch_accuracy:95.708155\n","test batch 560 test_batch_hit:495 test_batch_char:520 batch_accuracy:95.192308\n","test batch 576 test_batch_hit:685 test_batch_char:722 batch_accuracy:94.875346\n","test batch 592 test_batch_hit:813 test_batch_char:837 batch_accuracy:97.132616\n","test batch 608 test_batch_hit:633 test_batch_char:657 batch_accuracy:96.347032\n","test batch 624 test_batch_hit:635 test_batch_char:674 batch_accuracy:94.213650\n","test batch 640 test_batch_hit:497 test_batch_char:528 batch_accuracy:94.128788\n","test batch 656 test_batch_hit:526 test_batch_char:532 batch_accuracy:98.872180\n","test batch 672 test_batch_hit:693 test_batch_char:699 batch_accuracy:99.141631\n","test batch 688 test_batch_hit:751 test_batch_char:755 batch_accuracy:99.470199\n","test batch 704 test_batch_hit:728 test_batch_char:753 batch_accuracy:96.679947\n","test batch 720 test_batch_hit:775 test_batch_char:781 batch_accuracy:99.231754\n","test batch 736 test_batch_hit:985 test_batch_char:1001 batch_accuracy:98.401598\n","test batch 752 test_batch_hit:1129 test_batch_char:1129 batch_accuracy:100.000000\n","test batch 768 test_batch_hit:572 test_batch_char:616 batch_accuracy:92.857143\n","test batch 784 test_batch_hit:693 test_batch_char:727 batch_accuracy:95.323246\n","test batch 800 test_batch_hit:1018 test_batch_char:1052 batch_accuracy:96.768061\n","test batch 816 test_batch_hit:687 test_batch_char:687 batch_accuracy:100.000000\n","test batch 832 test_batch_hit:1024 test_batch_char:1092 batch_accuracy:93.772894\n","test batch 848 test_batch_hit:923 test_batch_char:929 batch_accuracy:99.354144\n","test batch 864 test_batch_hit:933 test_batch_char:970 batch_accuracy:96.185567\n","test batch 880 test_batch_hit:701 test_batch_char:704 batch_accuracy:99.573864\n","test batch 896 test_batch_hit:572 test_batch_char:587 batch_accuracy:97.444634\n","test batch 912 test_batch_hit:865 test_batch_char:865 batch_accuracy:100.000000\n","test batch 928 test_batch_hit:767 test_batch_char:778 batch_accuracy:98.586118\n","test batch 944 test_batch_hit:854 test_batch_char:880 batch_accuracy:97.045455\n","test batch 960 test_batch_hit:893 test_batch_char:897 batch_accuracy:99.554069\n","test batch 976 test_batch_hit:636 test_batch_char:636 batch_accuracy:100.000000\n","test batch 992 test_batch_hit:1076 test_batch_char:1083 batch_accuracy:99.353647\n","test batch 1008 test_batch_hit:819 test_batch_char:844 batch_accuracy:97.037915\n","test batch 1024 test_batch_hit:603 test_batch_char:648 batch_accuracy:93.055556\n","test batch 1040 test_batch_hit:657 test_batch_char:665 batch_accuracy:98.796992\n","test batch 1056 test_batch_hit:537 test_batch_char:554 batch_accuracy:96.931408\n","test batch 1072 test_batch_hit:835 test_batch_char:907 batch_accuracy:92.061742\n","test batch 1088 test_batch_hit:599 test_batch_char:620 batch_accuracy:96.612903\n","test batch 1104 test_batch_hit:906 test_batch_char:927 batch_accuracy:97.734628\n","test batch 1120 test_batch_hit:626 test_batch_char:656 batch_accuracy:95.426829\n","test batch 1136 test_batch_hit:550 test_batch_char:556 batch_accuracy:98.920863\n","test batch 1152 test_batch_hit:697 test_batch_char:723 batch_accuracy:96.403873\n","test batch 1168 test_batch_hit:748 test_batch_char:750 batch_accuracy:99.733333\n","test batch 1184 test_batch_hit:1151 test_batch_char:1169 batch_accuracy:98.460222\n","test batch 1200 test_batch_hit:521 test_batch_char:521 batch_accuracy:100.000000\n","test batch 1216 test_batch_hit:564 test_batch_char:564 batch_accuracy:100.000000\n","test batch 1232 test_batch_hit:662 test_batch_char:666 batch_accuracy:99.399399\n","test batch 1248 test_batch_hit:665 test_batch_char:667 batch_accuracy:99.700150\n","test batch 1264 test_batch_hit:788 test_batch_char:803 batch_accuracy:98.132005\n","test batch 1280 test_batch_hit:603 test_batch_char:613 batch_accuracy:98.368679\n","test batch 1296 test_batch_hit:639 test_batch_char:698 batch_accuracy:91.547278\n","test batch 1312 test_batch_hit:461 test_batch_char:488 batch_accuracy:94.467213\n","test batch 1328 test_batch_hit:492 test_batch_char:502 batch_accuracy:98.007968\n","test batch 1344 test_batch_hit:634 test_batch_char:657 batch_accuracy:96.499239\n","test batch 1360 test_batch_hit:750 test_batch_char:766 batch_accuracy:97.911227\n","test batch 1376 test_batch_hit:758 test_batch_char:784 batch_accuracy:96.683673\n","test batch 1392 test_batch_hit:582 test_batch_char:592 batch_accuracy:98.310811\n","test batch 1408 test_batch_hit:739 test_batch_char:753 batch_accuracy:98.140770\n","test batch 1424 test_batch_hit:938 test_batch_char:950 batch_accuracy:98.736842\n","test batch 1440 test_batch_hit:918 test_batch_char:929 batch_accuracy:98.815931\n","test batch 1456 test_batch_hit:907 test_batch_char:909 batch_accuracy:99.779978\n","test batch 1472 test_batch_hit:593 test_batch_char:604 batch_accuracy:98.178808\n","test batch 1488 test_batch_hit:598 test_batch_char:626 batch_accuracy:95.527157\n","test batch 1504 test_batch_hit:553 test_batch_char:605 batch_accuracy:91.404959\n","test batch 1520 test_batch_hit:667 test_batch_char:676 batch_accuracy:98.668639\n","test batch 1536 test_batch_hit:973 test_batch_char:973 batch_accuracy:100.000000\n","test batch 1552 test_batch_hit:934 test_batch_char:966 batch_accuracy:96.687371\n","test batch 1568 test_batch_hit:895 test_batch_char:920 batch_accuracy:97.282609\n","test batch 1584 test_batch_hit:974 test_batch_char:988 batch_accuracy:98.582996\n","test batch 1600 test_batch_hit:950 test_batch_char:970 batch_accuracy:97.938144\n","test batch 1616 test_batch_hit:1012 test_batch_char:1075 batch_accuracy:94.139535\n","test batch 1632 test_batch_hit:428 test_batch_char:442 batch_accuracy:96.832579\n","test batch 1648 test_batch_hit:595 test_batch_char:611 batch_accuracy:97.381342\n","test batch 1664 test_batch_hit:629 test_batch_char:652 batch_accuracy:96.472393\n","test batch 1680 test_batch_hit:644 test_batch_char:648 batch_accuracy:99.382716\n","test batch 1696 test_batch_hit:674 test_batch_char:679 batch_accuracy:99.263623\n","test batch 1712 test_batch_hit:596 test_batch_char:608 batch_accuracy:98.026316\n","test batch 1728 test_batch_hit:466 test_batch_char:503 batch_accuracy:92.644135\n","test batch 1744 test_batch_hit:595 test_batch_char:601 batch_accuracy:99.001664\n","test batch 1760 test_batch_hit:900 test_batch_char:912 batch_accuracy:98.684211\n","test batch 1776 test_batch_hit:752 test_batch_char:760 batch_accuracy:98.947368\n","test batch 1792 test_batch_hit:848 test_batch_char:867 batch_accuracy:97.808535\n","test batch 1808 test_batch_hit:754 test_batch_char:761 batch_accuracy:99.080158\n","test batch 1824 test_batch_hit:1028 test_batch_char:1044 batch_accuracy:98.467433\n","test batch 1840 test_batch_hit:856 test_batch_char:868 batch_accuracy:98.617512\n","test batch 1856 test_batch_hit:852 test_batch_char:859 batch_accuracy:99.185099\n","test batch 1872 test_batch_hit:655 test_batch_char:661 batch_accuracy:99.092284\n","test batch 1888 test_batch_hit:756 test_batch_char:780 batch_accuracy:96.923077\n","test batch 1904 test_batch_hit:1144 test_batch_char:1152 batch_accuracy:99.305556\n","test batch 1920 test_batch_hit:857 test_batch_char:897 batch_accuracy:95.540691\n","test batch 1936 test_batch_hit:916 test_batch_char:976 batch_accuracy:93.852459\n","test batch 1952 test_batch_hit:817 test_batch_char:844 batch_accuracy:96.800948\n","test batch 1968 test_batch_hit:675 test_batch_char:722 batch_accuracy:93.490305\n","test batch 1984 test_batch_hit:667 test_batch_char:681 batch_accuracy:97.944200\n","test batch 2000 test_batch_hit:971 test_batch_char:990 batch_accuracy:98.080808\n","test batch 2016 test_batch_hit:926 test_batch_char:928 batch_accuracy:99.784483\n","test batch 2032 test_batch_hit:856 test_batch_char:865 batch_accuracy:98.959538\n","test batch 2048 test_batch_hit:734 test_batch_char:759 batch_accuracy:96.706192\n","test batch 2064 test_batch_hit:738 test_batch_char:771 batch_accuracy:95.719844\n","test batch 2080 test_batch_hit:665 test_batch_char:681 batch_accuracy:97.650514\n","test batch 2096 test_batch_hit:741 test_batch_char:749 batch_accuracy:98.931909\n","test batch 2112 test_batch_hit:681 test_batch_char:710 batch_accuracy:95.915493\n","test batch 2128 test_batch_hit:852 test_batch_char:882 batch_accuracy:96.598639\n","test batch 2144 test_batch_hit:905 test_batch_char:919 batch_accuracy:98.476605\n","test batch 2160 test_batch_hit:530 test_batch_char:560 batch_accuracy:94.642857\n","test batch 2176 test_batch_hit:364 test_batch_char:377 batch_accuracy:96.551724\n","test batch 2192 test_batch_hit:473 test_batch_char:510 batch_accuracy:92.745098\n","test batch 2208 test_batch_hit:536 test_batch_char:552 batch_accuracy:97.101449\n","test batch 2224 test_batch_hit:763 test_batch_char:778 batch_accuracy:98.071979\n","test batch 2240 test_batch_hit:685 test_batch_char:696 batch_accuracy:98.419540\n","test batch 2256 test_batch_hit:546 test_batch_char:563 batch_accuracy:96.980462\n","test batch 2272 test_batch_hit:546 test_batch_char:575 batch_accuracy:94.956522\n","test batch 2288 test_batch_hit:497 test_batch_char:514 batch_accuracy:96.692607\n","test batch 2304 test_batch_hit:761 test_batch_char:789 batch_accuracy:96.451204\n","test batch 2320 test_batch_hit:788 test_batch_char:806 batch_accuracy:97.766749\n","test batch 2336 test_batch_hit:615 test_batch_char:621 batch_accuracy:99.033816\n","test batch 2352 test_batch_hit:736 test_batch_char:752 batch_accuracy:97.872340\n","test batch 2368 test_batch_hit:592 test_batch_char:612 batch_accuracy:96.732026\n","test batch 2384 test_batch_hit:847 test_batch_char:866 batch_accuracy:97.806005\n","test batch 2400 test_batch_hit:564 test_batch_char:564 batch_accuracy:100.000000\n","test batch 2416 test_batch_hit:742 test_batch_char:745 batch_accuracy:99.597315\n","test batch 2432 test_batch_hit:703 test_batch_char:711 batch_accuracy:98.874824\n","test batch 2448 test_batch_hit:721 test_batch_char:731 batch_accuracy:98.632011\n","test batch 2464 test_batch_hit:536 test_batch_char:544 batch_accuracy:98.529412\n","test batch 2480 test_batch_hit:953 test_batch_char:979 batch_accuracy:97.344229\n","test batch 2496 test_batch_hit:960 test_batch_char:991 batch_accuracy:96.871847\n","test batch 2512 test_batch_hit:811 test_batch_char:831 batch_accuracy:97.593261\n","test batch 2528 test_batch_hit:885 test_batch_char:930 batch_accuracy:95.161290\n","test batch 2544 test_batch_hit:710 test_batch_char:743 batch_accuracy:95.558546\n","test batch 2560 test_batch_hit:794 test_batch_char:810 batch_accuracy:98.024691\n","test batch 2576 test_batch_hit:1007 test_batch_char:1039 batch_accuracy:96.920115\n","test batch 2592 test_batch_hit:598 test_batch_char:610 batch_accuracy:98.032787\n","test batch 2608 test_batch_hit:651 test_batch_char:666 batch_accuracy:97.747748\n","test batch 2624 test_batch_hit:836 test_batch_char:868 batch_accuracy:96.313364\n","test batch 2640 test_batch_hit:600 test_batch_char:604 batch_accuracy:99.337748\n","test batch 2656 test_batch_hit:571 test_batch_char:585 batch_accuracy:97.606838\n","test batch 2672 test_batch_hit:590 test_batch_char:594 batch_accuracy:99.326599\n","test batch 2688 test_batch_hit:570 test_batch_char:573 batch_accuracy:99.476440\n","test batch 2704 test_batch_hit:1180 test_batch_char:1189 batch_accuracy:99.243061\n","test batch 2720 test_batch_hit:756 test_batch_char:762 batch_accuracy:99.212598\n","test batch 2736 test_batch_hit:457 test_batch_char:485 batch_accuracy:94.226804\n","test batch 2752 test_batch_hit:837 test_batch_char:859 batch_accuracy:97.438882\n","test batch 2768 test_batch_hit:796 test_batch_char:832 batch_accuracy:95.673077\n","test batch 2784 test_batch_hit:659 test_batch_char:671 batch_accuracy:98.211624\n","test batch 2800 test_batch_hit:821 test_batch_char:840 batch_accuracy:97.738095\n","test batch 2816 test_batch_hit:455 test_batch_char:486 batch_accuracy:93.621399\n","test batch 2832 test_batch_hit:460 test_batch_char:497 batch_accuracy:92.555332\n","test batch 2848 test_batch_hit:705 test_batch_char:747 batch_accuracy:94.377510\n","test batch 2864 test_batch_hit:574 test_batch_char:586 batch_accuracy:97.952218\n","test batch 2880 test_batch_hit:701 test_batch_char:709 batch_accuracy:98.871650\n","test batch 2896 test_batch_hit:853 test_batch_char:879 batch_accuracy:97.042093\n","test batch 2912 test_batch_hit:718 test_batch_char:725 batch_accuracy:99.034483\n","test batch 2928 test_batch_hit:436 test_batch_char:443 batch_accuracy:98.419865\n","test batch 2944 test_batch_hit:523 test_batch_char:529 batch_accuracy:98.865784\n","test batch 2960 test_batch_hit:912 test_batch_char:933 batch_accuracy:97.749196\n","test batch 2976 test_batch_hit:874 test_batch_char:884 batch_accuracy:98.868778\n","test batch 2992 test_batch_hit:569 test_batch_char:575 batch_accuracy:98.956522\n","test batch 3008 test_batch_hit:803 test_batch_char:814 batch_accuracy:98.648649\n","test batch 3024 test_batch_hit:684 test_batch_char:690 batch_accuracy:99.130435\n","test batch 3040 test_batch_hit:762 test_batch_char:780 batch_accuracy:97.692308\n","test batch 3056 test_batch_hit:705 test_batch_char:709 batch_accuracy:99.435825\n","test batch 3072 test_batch_hit:805 test_batch_char:813 batch_accuracy:99.015990\n","test batch 3088 test_batch_hit:895 test_batch_char:905 batch_accuracy:98.895028\n","test batch 3104 test_batch_hit:1007 test_batch_char:1013 batch_accuracy:99.407700\n","test batch 3120 test_batch_hit:616 test_batch_char:633 batch_accuracy:97.314376\n","test batch 3136 test_batch_hit:820 test_batch_char:830 batch_accuracy:98.795181\n","test batch 3152 test_batch_hit:934 test_batch_char:972 batch_accuracy:96.090535\n","test batch 3168 test_batch_hit:611 test_batch_char:629 batch_accuracy:97.138315\n","test batch 3184 test_batch_hit:629 test_batch_char:658 batch_accuracy:95.592705\n","test batch 3200 test_batch_hit:609 test_batch_char:621 batch_accuracy:98.067633\n","test batch 3216 test_batch_hit:661 test_batch_char:679 batch_accuracy:97.349043\n","test batch 3232 test_batch_hit:573 test_batch_char:612 batch_accuracy:93.627451\n","test batch 3248 test_batch_hit:764 test_batch_char:817 batch_accuracy:93.512852\n","test batch 3264 test_batch_hit:787 test_batch_char:854 batch_accuracy:92.154567\n","test batch 3280 test_batch_hit:664 test_batch_char:700 batch_accuracy:94.857143\n","test batch 3296 test_batch_hit:574 test_batch_char:578 batch_accuracy:99.307958\n","test batch 3312 test_batch_hit:729 test_batch_char:740 batch_accuracy:98.513514\n","test batch 3328 test_batch_hit:617 test_batch_char:626 batch_accuracy:98.562300\n","test batch 3344 test_batch_hit:768 test_batch_char:806 batch_accuracy:95.285360\n","test batch 3360 test_batch_hit:817 test_batch_char:850 batch_accuracy:96.117647\n","test batch 3376 test_batch_hit:930 test_batch_char:976 batch_accuracy:95.286885\n","test batch 3392 test_batch_hit:746 test_batch_char:792 batch_accuracy:94.191919\n","test batch 3408 test_batch_hit:626 test_batch_char:655 batch_accuracy:95.572519\n","test batch 3424 test_batch_hit:842 test_batch_char:890 batch_accuracy:94.606742\n","test batch 3440 test_batch_hit:770 test_batch_char:805 batch_accuracy:95.652174\n","test batch 3456 test_batch_hit:528 test_batch_char:566 batch_accuracy:93.286219\n","test batch 3472 test_batch_hit:607 test_batch_char:637 batch_accuracy:95.290424\n","test batch 3488 test_batch_hit:721 test_batch_char:754 batch_accuracy:95.623342\n","test batch 3504 test_batch_hit:529 test_batch_char:553 batch_accuracy:95.660036\n","test batch 3520 test_batch_hit:564 test_batch_char:589 batch_accuracy:95.755518\n","test batch 3536 test_batch_hit:472 test_batch_char:487 batch_accuracy:96.919918\n","test batch 3552 test_batch_hit:477 test_batch_char:490 batch_accuracy:97.346939\n","test batch 3568 test_batch_hit:747 test_batch_char:786 batch_accuracy:95.038168\n","test batch 3584 test_batch_hit:718 test_batch_char:734 batch_accuracy:97.820163\n","test batch 3600 test_batch_hit:889 test_batch_char:912 batch_accuracy:97.478070\n","test batch 3616 test_batch_hit:854 test_batch_char:881 batch_accuracy:96.935301\n","test batch 3632 test_batch_hit:823 test_batch_char:839 batch_accuracy:98.092968\n","test batch 3648 test_batch_hit:1061 test_batch_char:1077 batch_accuracy:98.514392\n","test batch 3664 test_batch_hit:892 test_batch_char:899 batch_accuracy:99.221357\n","test batch 3680 test_batch_hit:960 test_batch_char:966 batch_accuracy:99.378882\n","test batch 3696 test_batch_hit:958 test_batch_char:968 batch_accuracy:98.966942\n","test batch 3712 test_batch_hit:678 test_batch_char:699 batch_accuracy:96.995708\n","test batch 3728 test_batch_hit:918 test_batch_char:932 batch_accuracy:98.497854\n","test batch 3744 test_batch_hit:941 test_batch_char:959 batch_accuracy:98.123045\n","test batch 3760 test_batch_hit:785 test_batch_char:800 batch_accuracy:98.125000\n","test batch 3776 test_batch_hit:646 test_batch_char:648 batch_accuracy:99.691358\n","test batch 3792 test_batch_hit:770 test_batch_char:790 batch_accuracy:97.468354\n","test batch 3808 test_batch_hit:484 test_batch_char:502 batch_accuracy:96.414343\n","test batch 3824 test_batch_hit:660 test_batch_char:674 batch_accuracy:97.922849\n","test batch 3840 test_batch_hit:647 test_batch_char:684 batch_accuracy:94.590643\n","test batch 3856 test_batch_hit:593 test_batch_char:625 batch_accuracy:94.880000\n","test batch 3872 test_batch_hit:455 test_batch_char:479 batch_accuracy:94.989562\n","test batch 3888 test_batch_hit:813 test_batch_char:823 batch_accuracy:98.784933\n","test batch 3904 test_batch_hit:839 test_batch_char:863 batch_accuracy:97.219003\n","test batch 3920 test_batch_hit:866 test_batch_char:878 batch_accuracy:98.633257\n","test batch 3936 test_batch_hit:518 test_batch_char:549 batch_accuracy:94.353370\n","test batch 3952 test_batch_hit:912 test_batch_char:941 batch_accuracy:96.918172\n","test batch 3968 test_batch_hit:735 test_batch_char:750 batch_accuracy:98.000000\n","test batch 3984 test_batch_hit:64 test_batch_char:68 batch_accuracy:94.117647\n","test_hit:179412 test_all_char:184355 accuracy:97.318760\n","--------------------------------------------\n","accuracy is: 97.318760\n","Model saved in path: /content/gdrive/My Drive/NLPHW1/best_model_path97.31876000108485/model.ckpt\n","Train Epoch 2 loss 2.753930\n","--------------------------------\n","dev batch 0 loss 2.940475 dev_batch_hit:667 dev_batch_char:679 batch_accuracy:98.232695\n","dev batch 16 loss 2.819589 dev_batch_hit:686 dev_batch_char:711 batch_accuracy:96.483826\n","dev batch 32 loss 4.215164 dev_batch_hit:872 dev_batch_char:895 batch_accuracy:97.430168\n","dev batch 48 loss 1.799501 dev_batch_hit:801 dev_batch_char:807 batch_accuracy:99.256506\n","dev batch 64 loss 2.271005 dev_batch_hit:751 dev_batch_char:760 batch_accuracy:98.815789\n","dev batch 80 loss 2.967566 dev_batch_hit:903 dev_batch_char:927 batch_accuracy:97.411003\n","dev batch 96 loss 3.582905 dev_batch_hit:753 dev_batch_char:774 batch_accuracy:97.286822\n","dev batch 112 loss 3.017205 dev_batch_hit:668 dev_batch_char:684 batch_accuracy:97.660819\n","dev batch 128 loss 2.578646 dev_batch_hit:685 dev_batch_char:699 batch_accuracy:97.997139\n","dev batch 144 loss 2.453495 dev_batch_hit:807 dev_batch_char:826 batch_accuracy:97.699758\n","dev batch 160 loss 2.357731 dev_batch_hit:553 dev_batch_char:562 batch_accuracy:98.398577\n","dev batch 176 loss 4.092164 dev_batch_hit:861 dev_batch_char:894 batch_accuracy:96.308725\n","dev batch 192 loss 3.405670 dev_batch_hit:688 dev_batch_char:712 batch_accuracy:96.629213\n","dev batch 208 loss 2.516117 dev_batch_hit:623 dev_batch_char:642 batch_accuracy:97.040498\n","dev batch 224 loss 3.118541 dev_batch_hit:839 dev_batch_char:855 batch_accuracy:98.128655\n","dev batch 240 loss 3.544900 dev_batch_hit:751 dev_batch_char:777 batch_accuracy:96.653797\n","dev batch 256 loss 2.453240 dev_batch_hit:794 dev_batch_char:808 batch_accuracy:98.267327\n","dev batch 272 loss 2.497115 dev_batch_hit:619 dev_batch_char:630 batch_accuracy:98.253968\n","dev batch 288 loss 1.626094 dev_batch_hit:745 dev_batch_char:749 batch_accuracy:99.465955\n","dev batch 304 loss 2.263318 dev_batch_hit:735 dev_batch_char:745 batch_accuracy:98.657718\n","dev batch 320 loss 2.138071 dev_batch_hit:818 dev_batch_char:826 batch_accuracy:99.031477\n","dev batch 336 loss 2.945323 dev_batch_hit:849 dev_batch_char:869 batch_accuracy:97.698504\n","dev batch 352 loss 5.527425 dev_batch_hit:934 dev_batch_char:975 batch_accuracy:95.794872\n","dev batch 368 loss 2.101844 dev_batch_hit:753 dev_batch_char:765 batch_accuracy:98.431373\n","dev batch 384 loss 1.845865 dev_batch_hit:714 dev_batch_char:725 batch_accuracy:98.482759\n","dev batch 400 loss 1.679935 dev_batch_hit:750 dev_batch_char:756 batch_accuracy:99.206349\n","dev batch 416 loss 2.481018 dev_batch_hit:839 dev_batch_char:850 batch_accuracy:98.705882\n","dev batch 432 loss 3.625364 dev_batch_hit:668 dev_batch_char:700 batch_accuracy:95.428571\n","dev batch 448 loss 12.080116 dev_batch_hit:848 dev_batch_char:915 batch_accuracy:92.677596\n","dev batch 464 loss 2.117672 dev_batch_hit:775 dev_batch_char:783 batch_accuracy:98.978289\n","dev batch 480 loss 3.577317 dev_batch_hit:784 dev_batch_char:803 batch_accuracy:97.633873\n","dev batch 496 loss 1.770458 dev_batch_hit:780 dev_batch_char:790 batch_accuracy:98.734177\n","dev batch 512 loss 2.593768 dev_batch_hit:640 dev_batch_char:652 batch_accuracy:98.159509\n","dev batch 528 loss 2.138600 dev_batch_hit:638 dev_batch_char:646 batch_accuracy:98.761610\n","dev batch 544 loss 3.135540 dev_batch_hit:785 dev_batch_char:813 batch_accuracy:96.555966\n","dev batch 560 loss 1.724006 dev_batch_hit:538 dev_batch_char:542 batch_accuracy:99.261993\n","dev batch 576 loss 3.460183 dev_batch_hit:649 dev_batch_char:669 batch_accuracy:97.010463\n","dev batch 592 loss 3.354941 dev_batch_hit:874 dev_batch_char:895 batch_accuracy:97.653631\n","dev batch 608 loss 1.443975 dev_batch_hit:656 dev_batch_char:658 batch_accuracy:99.696049\n","dev batch 624 loss 2.161044 dev_batch_hit:635 dev_batch_char:645 batch_accuracy:98.449612\n","dev batch 640 loss 1.437394 dev_batch_hit:597 dev_batch_char:600 batch_accuracy:99.500000\n","dev batch 656 loss 2.346867 dev_batch_hit:669 dev_batch_char:684 batch_accuracy:97.807018\n","dev batch 672 loss 2.031825 dev_batch_hit:724 dev_batch_char:730 batch_accuracy:99.178082\n","dev batch 688 loss 1.841280 dev_batch_hit:705 dev_batch_char:712 batch_accuracy:99.016854\n","dev batch 704 loss 1.525537 dev_batch_hit:615 dev_batch_char:619 batch_accuracy:99.353796\n","dev batch 720 loss 1.563243 dev_batch_hit:771 dev_batch_char:773 batch_accuracy:99.741268\n","dev batch 736 loss 3.103523 dev_batch_hit:656 dev_batch_char:669 batch_accuracy:98.056801\n","dev batch 752 loss 4.653631 dev_batch_hit:721 dev_batch_char:750 batch_accuracy:96.133333\n","dev batch 768 loss 3.529819 dev_batch_hit:772 dev_batch_char:789 batch_accuracy:97.845374\n","dev batch 784 loss 3.341560 dev_batch_hit:712 dev_batch_char:733 batch_accuracy:97.135061\n","dev batch 800 loss 1.497524 dev_batch_hit:633 dev_batch_char:636 batch_accuracy:99.528302\n","dev batch 816 loss 2.550179 dev_batch_hit:671 dev_batch_char:687 batch_accuracy:97.671033\n","dev batch 832 loss 2.107196 dev_batch_hit:757 dev_batch_char:765 batch_accuracy:98.954248\n","dev batch 848 loss 2.285562 dev_batch_hit:572 dev_batch_char:586 batch_accuracy:97.610922\n","dev batch 864 loss 1.881355 dev_batch_hit:718 dev_batch_char:723 batch_accuracy:99.308437\n","dev batch 880 loss 3.513767 dev_batch_hit:715 dev_batch_char:731 batch_accuracy:97.811218\n","dev batch 896 loss 2.325589 dev_batch_hit:664 dev_batch_char:674 batch_accuracy:98.516320\n","dev batch 912 loss 2.802845 dev_batch_hit:720 dev_batch_char:735 batch_accuracy:97.959184\n","dev batch 928 loss 2.640505 dev_batch_hit:686 dev_batch_char:698 batch_accuracy:98.280802\n","dev batch 944 loss 2.308387 dev_batch_hit:897 dev_batch_char:907 batch_accuracy:98.897464\n","dev batch 960 loss 1.856281 dev_batch_hit:904 dev_batch_char:910 batch_accuracy:99.340659\n","dev batch 976 loss 4.563927 dev_batch_hit:667 dev_batch_char:693 batch_accuracy:96.248196\n","dev batch 992 loss 2.617205 dev_batch_hit:858 dev_batch_char:870 batch_accuracy:98.620690\n","dev batch 1008 loss 2.296014 dev_batch_hit:745 dev_batch_char:754 batch_accuracy:98.806366\n","dev batch 1024 loss 4.207244 dev_batch_hit:816 dev_batch_char:845 batch_accuracy:96.568047\n","dev batch 1040 loss 2.301694 dev_batch_hit:774 dev_batch_char:784 batch_accuracy:98.724490\n","dev batch 1056 loss 3.914508 dev_batch_hit:891 dev_batch_char:923 batch_accuracy:96.533044\n","dev batch 1072 loss 1.878962 dev_batch_hit:749 dev_batch_char:756 batch_accuracy:99.074074\n","dev batch 1088 loss 2.324351 dev_batch_hit:714 dev_batch_char:729 batch_accuracy:97.942387\n","dev batch 1104 loss 2.695635 dev_batch_hit:600 dev_batch_char:619 batch_accuracy:96.930533\n","dev batch 1120 loss 3.173874 dev_batch_hit:849 dev_batch_char:865 batch_accuracy:98.150289\n","dev batch 1136 loss 2.448631 dev_batch_hit:685 dev_batch_char:694 batch_accuracy:98.703170\n","dev batch 1152 loss 1.845578 dev_batch_hit:646 dev_batch_char:651 batch_accuracy:99.231951\n","dev batch 1168 loss 3.995201 dev_batch_hit:538 dev_batch_char:562 batch_accuracy:95.729537\n","dev batch 1184 loss 2.494236 dev_batch_hit:747 dev_batch_char:761 batch_accuracy:98.160315\n","dev batch 1200 loss 2.056645 dev_batch_hit:660 dev_batch_char:671 batch_accuracy:98.360656\n","dev batch 1216 loss 1.414117 dev_batch_hit:628 dev_batch_char:630 batch_accuracy:99.682540\n","dev batch 1232 loss 2.949930 dev_batch_hit:638 dev_batch_char:655 batch_accuracy:97.404580\n","dev batch 1248 loss 2.735545 dev_batch_hit:603 dev_batch_char:616 batch_accuracy:97.889610\n","dev batch 1264 loss 2.713534 dev_batch_hit:771 dev_batch_char:791 batch_accuracy:97.471555\n","dev batch 1280 loss 3.279887 dev_batch_hit:867 dev_batch_char:893 batch_accuracy:97.088466\n","dev batch 1296 loss 2.898361 dev_batch_hit:794 dev_batch_char:815 batch_accuracy:97.423313\n","dev batch 1312 loss 2.064653 dev_batch_hit:647 dev_batch_char:657 batch_accuracy:98.477930\n","dev batch 1328 loss 3.772716 dev_batch_hit:958 dev_batch_char:981 batch_accuracy:97.655454\n","dev batch 1344 loss 1.962369 dev_batch_hit:874 dev_batch_char:886 batch_accuracy:98.645598\n","dev batch 1360 loss 3.057300 dev_batch_hit:783 dev_batch_char:799 batch_accuracy:97.997497\n","dev batch 1376 loss 1.951140 dev_batch_hit:805 dev_batch_char:807 batch_accuracy:99.752169\n","dev batch 1392 loss 2.264425 dev_batch_hit:788 dev_batch_char:800 batch_accuracy:98.500000\n","dev batch 1408 loss 3.417622 dev_batch_hit:794 dev_batch_char:816 batch_accuracy:97.303922\n","dev batch 1424 loss 2.816037 dev_batch_hit:721 dev_batch_char:739 batch_accuracy:97.564276\n","dev batch 1440 loss 2.674202 dev_batch_hit:842 dev_batch_char:852 batch_accuracy:98.826291\n","dev batch 1456 loss 3.683589 dev_batch_hit:708 dev_batch_char:735 batch_accuracy:96.326531\n","dev batch 1472 loss 2.979517 dev_batch_hit:743 dev_batch_char:759 batch_accuracy:97.891963\n","dev batch 1488 loss 2.502991 dev_batch_hit:839 dev_batch_char:850 batch_accuracy:98.705882\n","dev batch 1504 loss 1.776250 dev_batch_hit:607 dev_batch_char:611 batch_accuracy:99.345336\n","dev batch 1520 loss 2.342006 dev_batch_hit:616 dev_batch_char:633 batch_accuracy:97.314376\n","dev batch 1536 loss 2.890155 dev_batch_hit:858 dev_batch_char:872 batch_accuracy:98.394495\n","dev batch 1552 loss 2.424182 dev_batch_hit:832 dev_batch_char:860 batch_accuracy:96.744186\n","dev batch 1568 loss 2.490819 dev_batch_hit:702 dev_batch_char:718 batch_accuracy:97.771588\n","dev batch 1584 loss 2.530950 dev_batch_hit:700 dev_batch_char:716 batch_accuracy:97.765363\n","dev batch 1600 loss 2.478306 dev_batch_hit:747 dev_batch_char:755 batch_accuracy:98.940397\n","dev batch 1616 loss 2.043938 dev_batch_hit:666 dev_batch_char:678 batch_accuracy:98.230088\n","dev batch 1632 loss 3.341678 dev_batch_hit:872 dev_batch_char:888 batch_accuracy:98.198198\n","dev batch 1648 loss 3.188545 dev_batch_hit:725 dev_batch_char:756 batch_accuracy:95.899471\n","dev batch 1664 loss 3.771382 dev_batch_hit:749 dev_batch_char:765 batch_accuracy:97.908497\n","dev batch 1680 loss 1.987668 dev_batch_hit:842 dev_batch_char:850 batch_accuracy:99.058824\n","dev batch 1696 loss 1.840575 dev_batch_hit:665 dev_batch_char:673 batch_accuracy:98.811293\n","dev batch 1712 loss 3.002852 dev_batch_hit:667 dev_batch_char:685 batch_accuracy:97.372263\n","dev batch 1728 loss 2.858581 dev_batch_hit:859 dev_batch_char:881 batch_accuracy:97.502838\n","dev batch 1744 loss 2.912261 dev_batch_hit:647 dev_batch_char:666 batch_accuracy:97.147147\n","dev batch 1760 loss 2.465230 dev_batch_hit:828 dev_batch_char:842 batch_accuracy:98.337292\n","dev batch 1776 loss 2.299626 dev_batch_hit:719 dev_batch_char:732 batch_accuracy:98.224044\n","dev batch 1792 loss 3.427835 dev_batch_hit:893 dev_batch_char:934 batch_accuracy:95.610278\n","dev batch 1808 loss 3.798456 dev_batch_hit:801 dev_batch_char:826 batch_accuracy:96.973366\n","dev batch 1824 loss 3.053635 dev_batch_hit:829 dev_batch_char:843 batch_accuracy:98.339265\n","dev batch 1840 loss 2.243027 dev_batch_hit:730 dev_batch_char:741 batch_accuracy:98.515520\n","dev batch 1856 loss 3.637014 dev_batch_hit:737 dev_batch_char:757 batch_accuracy:97.357992\n","dev batch 1872 loss 2.869337 dev_batch_hit:735 dev_batch_char:745 batch_accuracy:98.657718\n","dev batch 1888 loss 2.499574 dev_batch_hit:620 dev_batch_char:631 batch_accuracy:98.256735\n","dev batch 1904 loss 2.343511 dev_batch_hit:715 dev_batch_char:725 batch_accuracy:98.620690\n","dev batch 1920 loss 2.203817 dev_batch_hit:614 dev_batch_char:620 batch_accuracy:99.032258\n","dev batch 1936 loss 3.316801 dev_batch_hit:635 dev_batch_char:657 batch_accuracy:96.651446\n","dev batch 1952 loss 1.936687 dev_batch_hit:657 dev_batch_char:665 batch_accuracy:98.796992\n","dev batch 1968 loss 3.779271 dev_batch_hit:841 dev_batch_char:860 batch_accuracy:97.790698\n","dev batch 1984 loss 2.491995 dev_batch_hit:725 dev_batch_char:735 batch_accuracy:98.639456\n","dev batch 2000 loss 2.641487 dev_batch_hit:648 dev_batch_char:663 batch_accuracy:97.737557\n","dev batch 2016 loss 2.070185 dev_batch_hit:672 dev_batch_char:681 batch_accuracy:98.678414\n","dev batch 2032 loss 1.410826 dev_batch_hit:809 dev_batch_char:811 batch_accuracy:99.753391\n","dev batch 2048 loss 2.213686 dev_batch_hit:727 dev_batch_char:732 batch_accuracy:99.316940\n","dev batch 2064 loss 1.815584 dev_batch_hit:603 dev_batch_char:609 batch_accuracy:99.014778\n","dev batch 2080 loss 2.879506 dev_batch_hit:678 dev_batch_char:695 batch_accuracy:97.553957\n","dev batch 2096 loss 1.592605 dev_batch_hit:652 dev_batch_char:657 batch_accuracy:99.238965\n","dev batch 2112 loss 1.998417 dev_batch_hit:747 dev_batch_char:762 batch_accuracy:98.031496\n","dev batch 2128 loss 2.652468 dev_batch_hit:876 dev_batch_char:889 batch_accuracy:98.537683\n","dev batch 2144 loss 2.509948 dev_batch_hit:656 dev_batch_char:670 batch_accuracy:97.910448\n","dev batch 2160 loss 2.520288 dev_batch_hit:820 dev_batch_char:830 batch_accuracy:98.795181\n","dev batch 2176 loss 3.261651 dev_batch_hit:678 dev_batch_char:703 batch_accuracy:96.443812\n","dev batch 2192 loss 1.726015 dev_batch_hit:690 dev_batch_char:694 batch_accuracy:99.423631\n","dev batch 2208 loss 2.609396 dev_batch_hit:847 dev_batch_char:861 batch_accuracy:98.373984\n","dev batch 2224 loss 2.062291 dev_batch_hit:695 dev_batch_char:700 batch_accuracy:99.285714\n","dev batch 2240 loss 2.508758 dev_batch_hit:696 dev_batch_char:709 batch_accuracy:98.166432\n","dev batch 2256 loss 2.112829 dev_batch_hit:680 dev_batch_char:695 batch_accuracy:97.841727\n","dev batch 2272 loss 4.435772 dev_batch_hit:881 dev_batch_char:911 batch_accuracy:96.706915\n","dev batch 2288 loss 2.418304 dev_batch_hit:643 dev_batch_char:653 batch_accuracy:98.468606\n","dev batch 2304 loss 3.154459 dev_batch_hit:840 dev_batch_char:867 batch_accuracy:96.885813\n","dev batch 2320 loss 2.203529 dev_batch_hit:723 dev_batch_char:739 batch_accuracy:97.834912\n","dev batch 2336 loss 1.722138 dev_batch_hit:622 dev_batch_char:626 batch_accuracy:99.361022\n","dev batch 2352 loss 2.124347 dev_batch_hit:594 dev_batch_char:604 batch_accuracy:98.344371\n","dev batch 2368 loss 1.754393 dev_batch_hit:739 dev_batch_char:746 batch_accuracy:99.061662\n","dev batch 2384 loss 2.317315 dev_batch_hit:681 dev_batch_char:695 batch_accuracy:97.985612\n","dev batch 2400 loss 2.089815 dev_batch_hit:692 dev_batch_char:705 batch_accuracy:98.156028\n","dev batch 2416 loss 1.867972 dev_batch_hit:755 dev_batch_char:760 batch_accuracy:99.342105\n","dev batch 2432 loss 2.407329 dev_batch_hit:625 dev_batch_char:637 batch_accuracy:98.116170\n","dev batch 2448 loss 4.306183 dev_batch_hit:923 dev_batch_char:952 batch_accuracy:96.953782\n","dev batch 2464 loss 2.682592 dev_batch_hit:733 dev_batch_char:748 batch_accuracy:97.994652\n","dev batch 2480 loss 2.537742 dev_batch_hit:666 dev_batch_char:682 batch_accuracy:97.653959\n","dev batch 2496 loss 3.956452 dev_batch_hit:867 dev_batch_char:894 batch_accuracy:96.979866\n","dev batch 2512 loss 2.608580 dev_batch_hit:751 dev_batch_char:761 batch_accuracy:98.685940\n","dev batch 2528 loss 2.636405 dev_batch_hit:871 dev_batch_char:881 batch_accuracy:98.864926\n","dev batch 2544 loss 3.925791 dev_batch_hit:826 dev_batch_char:861 batch_accuracy:95.934959\n","dev batch 2560 loss 2.562126 dev_batch_hit:457 dev_batch_char:472 batch_accuracy:96.822034\n","dev batch 2576 loss 2.525768 dev_batch_hit:821 dev_batch_char:831 batch_accuracy:98.796631\n","dev batch 2592 loss 2.318731 dev_batch_hit:669 dev_batch_char:682 batch_accuracy:98.093842\n","dev batch 2608 loss 2.784827 dev_batch_hit:786 dev_batch_char:805 batch_accuracy:97.639752\n","dev batch 2624 loss 2.722986 dev_batch_hit:724 dev_batch_char:734 batch_accuracy:98.637602\n","dev batch 2640 loss 3.572128 dev_batch_hit:691 dev_batch_char:710 batch_accuracy:97.323944\n","dev batch 2656 loss 1.687902 dev_batch_hit:745 dev_batch_char:749 batch_accuracy:99.465955\n","dev batch 2672 loss 2.150752 dev_batch_hit:973 dev_batch_char:979 batch_accuracy:99.387130\n","dev batch 2688 loss 2.452781 dev_batch_hit:619 dev_batch_char:631 batch_accuracy:98.098257\n","dev batch 2704 loss 1.505213 dev_batch_hit:716 dev_batch_char:720 batch_accuracy:99.444444\n","dev batch 2720 loss 2.614436 dev_batch_hit:650 dev_batch_char:668 batch_accuracy:97.305389\n","dev batch 2736 loss 1.548200 dev_batch_hit:528 dev_batch_char:530 batch_accuracy:99.622642\n","dev batch 2752 loss 2.241138 dev_batch_hit:708 dev_batch_char:716 batch_accuracy:98.882682\n","dev batch 2768 loss 2.577939 dev_batch_hit:757 dev_batch_char:769 batch_accuracy:98.439532\n","dev batch 2784 loss 3.182230 dev_batch_hit:784 dev_batch_char:800 batch_accuracy:98.000000\n","dev batch 2800 loss 2.001286 dev_batch_hit:871 dev_batch_char:879 batch_accuracy:99.089875\n","dev batch 2816 loss 1.682775 dev_batch_hit:712 dev_batch_char:720 batch_accuracy:98.888889\n","dev batch 2832 loss 2.421240 dev_batch_hit:857 dev_batch_char:869 batch_accuracy:98.619102\n","dev batch 2848 loss 2.392945 dev_batch_hit:677 dev_batch_char:683 batch_accuracy:99.121523\n","dev batch 2864 loss 2.261915 dev_batch_hit:647 dev_batch_char:655 batch_accuracy:98.778626\n","dev batch 2880 loss 3.241780 dev_batch_hit:984 dev_batch_char:1006 batch_accuracy:97.813121\n","dev batch 2896 loss 1.950290 dev_batch_hit:660 dev_batch_char:670 batch_accuracy:98.507463\n","dev batch 2912 loss 2.406043 dev_batch_hit:712 dev_batch_char:728 batch_accuracy:97.802198\n","dev batch 2928 loss 2.711549 dev_batch_hit:652 dev_batch_char:671 batch_accuracy:97.168405\n","dev batch 2944 loss 1.743007 dev_batch_hit:752 dev_batch_char:758 batch_accuracy:99.208443\n","dev batch 2960 loss 2.010473 dev_batch_hit:539 dev_batch_char:548 batch_accuracy:98.357664\n","dev batch 2976 loss 2.351154 dev_batch_hit:710 dev_batch_char:721 batch_accuracy:98.474341\n","dev batch 2992 loss 3.319312 dev_batch_hit:768 dev_batch_char:807 batch_accuracy:95.167286\n","dev batch 3008 loss 3.609504 dev_batch_hit:781 dev_batch_char:807 batch_accuracy:96.778191\n","dev batch 3024 loss 2.189123 dev_batch_hit:864 dev_batch_char:872 batch_accuracy:99.082569\n","dev batch 3040 loss 2.978506 dev_batch_hit:578 dev_batch_char:595 batch_accuracy:97.142857\n","dev batch 3056 loss 2.925636 dev_batch_hit:653 dev_batch_char:670 batch_accuracy:97.462687\n","dev batch 3072 loss 2.279277 dev_batch_hit:667 dev_batch_char:674 batch_accuracy:98.961424\n","dev batch 3088 loss 2.460052 dev_batch_hit:571 dev_batch_char:583 batch_accuracy:97.941681\n","dev batch 3104 loss 2.022638 dev_batch_hit:770 dev_batch_char:783 batch_accuracy:98.339719\n","dev batch 3120 loss 2.207117 dev_batch_hit:975 dev_batch_char:985 batch_accuracy:98.984772\n","dev batch 3136 loss 2.442502 dev_batch_hit:769 dev_batch_char:779 batch_accuracy:98.716303\n","dev batch 3152 loss 3.655875 dev_batch_hit:676 dev_batch_char:692 batch_accuracy:97.687861\n","dev batch 3168 loss 1.588742 dev_batch_hit:626 dev_batch_char:628 batch_accuracy:99.681529\n","dev batch 3184 loss 1.725401 dev_batch_hit:846 dev_batch_char:850 batch_accuracy:99.529412\n","dev batch 3200 loss 2.218458 dev_batch_hit:741 dev_batch_char:749 batch_accuracy:98.931909\n","dev batch 3216 loss 3.782940 dev_batch_hit:908 dev_batch_char:929 batch_accuracy:97.739505\n","dev batch 3232 loss 2.151100 dev_batch_hit:588 dev_batch_char:598 batch_accuracy:98.327759\n","dev batch 3248 loss 2.535890 dev_batch_hit:689 dev_batch_char:702 batch_accuracy:98.148148\n","dev batch 3264 loss 3.294848 dev_batch_hit:706 dev_batch_char:733 batch_accuracy:96.316508\n","dev batch 3280 loss 2.088316 dev_batch_hit:747 dev_batch_char:759 batch_accuracy:98.418972\n","dev batch 3296 loss 1.835944 dev_batch_hit:575 dev_batch_char:587 batch_accuracy:97.955707\n","dev batch 3312 loss 2.474664 dev_batch_hit:797 dev_batch_char:812 batch_accuracy:98.152709\n","dev batch 3328 loss 5.326827 dev_batch_hit:766 dev_batch_char:795 batch_accuracy:96.352201\n","dev batch 3344 loss 2.012352 dev_batch_hit:757 dev_batch_char:770 batch_accuracy:98.311688\n","dev batch 3360 loss 4.075668 dev_batch_hit:782 dev_batch_char:804 batch_accuracy:97.263682\n","dev batch 3376 loss 2.550033 dev_batch_hit:711 dev_batch_char:721 batch_accuracy:98.613037\n","dev batch 3392 loss 2.860883 dev_batch_hit:768 dev_batch_char:791 batch_accuracy:97.092288\n","dev batch 3408 loss 3.636089 dev_batch_hit:657 dev_batch_char:680 batch_accuracy:96.617647\n","dev batch 3424 loss 2.327912 dev_batch_hit:905 dev_batch_char:919 batch_accuracy:98.476605\n","dev batch 3440 loss 1.820583 dev_batch_hit:563 dev_batch_char:571 batch_accuracy:98.598949\n","dev batch 3456 loss 2.239818 dev_batch_hit:886 dev_batch_char:898 batch_accuracy:98.663697\n","dev batch 3472 loss 3.438697 dev_batch_hit:862 dev_batch_char:880 batch_accuracy:97.954545\n","dev batch 3488 loss 4.125486 dev_batch_hit:569 dev_batch_char:587 batch_accuracy:96.933560\n","dev batch 3504 loss 4.228141 dev_batch_hit:844 dev_batch_char:874 batch_accuracy:96.567506\n","dev batch 3520 loss 1.622206 dev_batch_hit:587 dev_batch_char:589 batch_accuracy:99.660441\n","dev batch 3536 loss 1.863548 dev_batch_hit:627 dev_batch_char:635 batch_accuracy:98.740157\n","dev batch 3552 loss 2.228368 dev_batch_hit:598 dev_batch_char:604 batch_accuracy:99.006623\n","dev batch 3568 loss 1.908839 dev_batch_hit:835 dev_batch_char:843 batch_accuracy:99.051008\n","dev batch 3584 loss 3.481372 dev_batch_hit:844 dev_batch_char:860 batch_accuracy:98.139535\n","dev batch 3600 loss 1.813805 dev_batch_hit:732 dev_batch_char:736 batch_accuracy:99.456522\n","dev batch 3616 loss 1.443493 dev_batch_hit:775 dev_batch_char:777 batch_accuracy:99.742600\n","dev batch 3632 loss 2.227459 dev_batch_hit:655 dev_batch_char:662 batch_accuracy:98.942598\n","dev batch 3648 loss 1.826758 dev_batch_hit:784 dev_batch_char:788 batch_accuracy:99.492386\n","dev batch 3664 loss 2.299887 dev_batch_hit:708 dev_batch_char:719 batch_accuracy:98.470097\n","dev batch 3680 loss 1.748749 dev_batch_hit:704 dev_batch_char:708 batch_accuracy:99.435028\n","dev batch 3696 loss 1.702513 dev_batch_hit:888 dev_batch_char:892 batch_accuracy:99.551570\n","dev batch 3712 loss 2.140126 dev_batch_hit:635 dev_batch_char:648 batch_accuracy:97.993827\n","dev batch 3728 loss 2.567715 dev_batch_hit:741 dev_batch_char:751 batch_accuracy:98.668442\n","dev batch 3744 loss 2.482757 dev_batch_hit:631 dev_batch_char:647 batch_accuracy:97.527048\n","dev batch 3760 loss 2.620373 dev_batch_hit:720 dev_batch_char:733 batch_accuracy:98.226467\n","dev batch 3776 loss 2.329346 dev_batch_hit:781 dev_batch_char:800 batch_accuracy:97.625000\n","dev batch 3792 loss 1.971544 dev_batch_hit:573 dev_batch_char:578 batch_accuracy:99.134948\n","dev batch 3808 loss 2.062203 dev_batch_hit:548 dev_batch_char:557 batch_accuracy:98.384201\n","dev batch 3824 loss 1.780469 dev_batch_hit:794 dev_batch_char:801 batch_accuracy:99.126092\n","dev batch 3840 loss 3.537097 dev_batch_hit:887 dev_batch_char:909 batch_accuracy:97.579758\n","dev batch 3856 loss 2.508689 dev_batch_hit:742 dev_batch_char:752 batch_accuracy:98.670213\n","dev batch 3872 loss 3.126331 dev_batch_hit:675 dev_batch_char:696 batch_accuracy:96.982759\n","dev batch 3888 loss 1.974020 dev_batch_hit:1003 dev_batch_char:1014 batch_accuracy:98.915187\n","dev batch 3904 loss 3.495766 dev_batch_hit:758 dev_batch_char:780 batch_accuracy:97.179487\n","dev batch 3920 loss 1.831600 dev_batch_hit:618 dev_batch_char:624 batch_accuracy:99.038462\n","dev batch 3936 loss 2.748534 dev_batch_hit:641 dev_batch_char:655 batch_accuracy:97.862595\n","dev batch 3952 loss 2.154415 dev_batch_hit:775 dev_batch_char:785 batch_accuracy:98.726115\n","dev batch 3968 loss 2.722509 dev_batch_hit:899 dev_batch_char:913 batch_accuracy:98.466594\n","dev batch 3984 loss 3.276563 dev_batch_hit:847 dev_batch_char:871 batch_accuracy:97.244546\n","dev batch 4000 loss 1.952636 dev_batch_hit:830 dev_batch_char:836 batch_accuracy:99.282297\n","dev batch 4016 loss 2.214980 dev_batch_hit:742 dev_batch_char:757 batch_accuracy:98.018494\n","dev batch 4032 loss 4.157480 dev_batch_hit:821 dev_batch_char:842 batch_accuracy:97.505938\n","dev batch 4048 loss 2.278353 dev_batch_hit:669 dev_batch_char:677 batch_accuracy:98.818316\n","dev batch 4064 loss 1.513526 dev_batch_hit:801 dev_batch_char:803 batch_accuracy:99.750934\n","dev batch 4080 loss 3.752751 dev_batch_hit:652 dev_batch_char:673 batch_accuracy:96.879643\n","dev batch 4096 loss 2.601328 dev_batch_hit:716 dev_batch_char:728 batch_accuracy:98.351648\n","dev batch 4112 loss 2.837341 dev_batch_hit:817 dev_batch_char:840 batch_accuracy:97.261905\n","dev batch 4128 loss 1.710703 dev_batch_hit:981 dev_batch_char:987 batch_accuracy:99.392097\n","dev batch 4144 loss 2.820843 dev_batch_hit:654 dev_batch_char:666 batch_accuracy:98.198198\n","dev batch 4160 loss 2.150554 dev_batch_hit:558 dev_batch_char:569 batch_accuracy:98.066784\n","dev batch 4176 loss 2.333066 dev_batch_hit:797 dev_batch_char:807 batch_accuracy:98.760843\n","dev batch 4192 loss 2.573595 dev_batch_hit:789 dev_batch_char:797 batch_accuracy:98.996236\n","dev batch 4208 loss 1.990852 dev_batch_hit:678 dev_batch_char:683 batch_accuracy:99.267936\n","dev batch 4224 loss 2.157317 dev_batch_hit:713 dev_batch_char:723 batch_accuracy:98.616874\n","dev batch 4240 loss 3.374498 dev_batch_hit:742 dev_batch_char:759 batch_accuracy:97.760211\n","dev batch 4256 loss 2.780269 dev_batch_hit:720 dev_batch_char:737 batch_accuracy:97.693351\n","dev batch 4272 loss 1.847606 dev_batch_hit:1154 dev_batch_char:1161 batch_accuracy:99.397071\n","dev batch 4288 loss 4.012127 dev_batch_hit:616 dev_batch_char:641 batch_accuracy:96.099844\n","dev batch 4304 loss 2.565993 dev_batch_hit:820 dev_batch_char:831 batch_accuracy:98.676294\n","dev batch 4320 loss 2.512452 dev_batch_hit:642 dev_batch_char:651 batch_accuracy:98.617512\n","dev batch 4336 loss 1.326835 dev_batch_hit:447 dev_batch_char:447 batch_accuracy:100.000000\n","Valid Epoch 2 loss 2.626881\n","dev_hit_all:199918 dev_all_char:203715 accuracy:98.136122\n","--------------------------------\n","test batch 0 test_batch_hit:393 test_batch_char:400 batch_accuracy:98.250000\n","test batch 16 test_batch_hit:547 test_batch_char:554 batch_accuracy:98.736462\n","test batch 32 test_batch_hit:558 test_batch_char:573 batch_accuracy:97.382199\n","test batch 48 test_batch_hit:540 test_batch_char:550 batch_accuracy:98.181818\n","test batch 64 test_batch_hit:712 test_batch_char:716 batch_accuracy:99.441341\n","test batch 80 test_batch_hit:592 test_batch_char:617 batch_accuracy:95.948136\n","test batch 96 test_batch_hit:454 test_batch_char:492 batch_accuracy:92.276423\n","test batch 112 test_batch_hit:551 test_batch_char:592 batch_accuracy:93.074324\n","test batch 128 test_batch_hit:712 test_batch_char:726 batch_accuracy:98.071625\n","test batch 144 test_batch_hit:717 test_batch_char:735 batch_accuracy:97.551020\n","test batch 160 test_batch_hit:488 test_batch_char:511 batch_accuracy:95.499022\n","test batch 176 test_batch_hit:486 test_batch_char:490 batch_accuracy:99.183673\n","test batch 192 test_batch_hit:400 test_batch_char:412 batch_accuracy:97.087379\n","test batch 208 test_batch_hit:520 test_batch_char:532 batch_accuracy:97.744361\n","test batch 224 test_batch_hit:503 test_batch_char:510 batch_accuracy:98.627451\n","test batch 240 test_batch_hit:714 test_batch_char:729 batch_accuracy:97.942387\n","test batch 256 test_batch_hit:563 test_batch_char:574 batch_accuracy:98.083624\n","test batch 272 test_batch_hit:518 test_batch_char:537 batch_accuracy:96.461825\n","test batch 288 test_batch_hit:717 test_batch_char:728 batch_accuracy:98.489011\n","test batch 304 test_batch_hit:1120 test_batch_char:1137 batch_accuracy:98.504837\n","test batch 320 test_batch_hit:922 test_batch_char:928 batch_accuracy:99.353448\n","test batch 336 test_batch_hit:682 test_batch_char:702 batch_accuracy:97.150997\n","test batch 352 test_batch_hit:1052 test_batch_char:1068 batch_accuracy:98.501873\n","test batch 368 test_batch_hit:756 test_batch_char:775 batch_accuracy:97.548387\n","test batch 384 test_batch_hit:890 test_batch_char:910 batch_accuracy:97.802198\n","test batch 400 test_batch_hit:556 test_batch_char:575 batch_accuracy:96.695652\n","test batch 416 test_batch_hit:758 test_batch_char:832 batch_accuracy:91.105769\n","test batch 432 test_batch_hit:862 test_batch_char:895 batch_accuracy:96.312849\n","test batch 448 test_batch_hit:713 test_batch_char:720 batch_accuracy:99.027778\n","test batch 464 test_batch_hit:493 test_batch_char:500 batch_accuracy:98.600000\n","test batch 480 test_batch_hit:817 test_batch_char:821 batch_accuracy:99.512789\n","test batch 496 test_batch_hit:581 test_batch_char:598 batch_accuracy:97.157191\n","test batch 512 test_batch_hit:978 test_batch_char:988 batch_accuracy:98.987854\n","test batch 528 test_batch_hit:493 test_batch_char:503 batch_accuracy:98.011928\n","test batch 544 test_batch_hit:667 test_batch_char:699 batch_accuracy:95.422031\n","test batch 560 test_batch_hit:507 test_batch_char:520 batch_accuracy:97.500000\n","test batch 576 test_batch_hit:687 test_batch_char:722 batch_accuracy:95.152355\n","test batch 592 test_batch_hit:822 test_batch_char:837 batch_accuracy:98.207885\n","test batch 608 test_batch_hit:637 test_batch_char:657 batch_accuracy:96.955860\n","test batch 624 test_batch_hit:644 test_batch_char:674 batch_accuracy:95.548961\n","test batch 640 test_batch_hit:511 test_batch_char:528 batch_accuracy:96.780303\n","test batch 656 test_batch_hit:524 test_batch_char:532 batch_accuracy:98.496241\n","test batch 672 test_batch_hit:694 test_batch_char:699 batch_accuracy:99.284692\n","test batch 688 test_batch_hit:749 test_batch_char:755 batch_accuracy:99.205298\n","test batch 704 test_batch_hit:736 test_batch_char:753 batch_accuracy:97.742364\n","test batch 720 test_batch_hit:773 test_batch_char:781 batch_accuracy:98.975672\n","test batch 736 test_batch_hit:995 test_batch_char:1001 batch_accuracy:99.400599\n","test batch 752 test_batch_hit:1129 test_batch_char:1129 batch_accuracy:100.000000\n","test batch 768 test_batch_hit:574 test_batch_char:616 batch_accuracy:93.181818\n","test batch 784 test_batch_hit:693 test_batch_char:727 batch_accuracy:95.323246\n","test batch 800 test_batch_hit:1034 test_batch_char:1052 batch_accuracy:98.288973\n","test batch 816 test_batch_hit:685 test_batch_char:687 batch_accuracy:99.708879\n","test batch 832 test_batch_hit:1025 test_batch_char:1092 batch_accuracy:93.864469\n","test batch 848 test_batch_hit:925 test_batch_char:929 batch_accuracy:99.569429\n","test batch 864 test_batch_hit:944 test_batch_char:970 batch_accuracy:97.319588\n","test batch 880 test_batch_hit:704 test_batch_char:704 batch_accuracy:100.000000\n","test batch 896 test_batch_hit:575 test_batch_char:587 batch_accuracy:97.955707\n","test batch 912 test_batch_hit:863 test_batch_char:865 batch_accuracy:99.768786\n","test batch 928 test_batch_hit:773 test_batch_char:778 batch_accuracy:99.357326\n","test batch 944 test_batch_hit:852 test_batch_char:880 batch_accuracy:96.818182\n","test batch 960 test_batch_hit:893 test_batch_char:897 batch_accuracy:99.554069\n","test batch 976 test_batch_hit:628 test_batch_char:636 batch_accuracy:98.742138\n","test batch 992 test_batch_hit:1077 test_batch_char:1083 batch_accuracy:99.445983\n","test batch 1008 test_batch_hit:805 test_batch_char:844 batch_accuracy:95.379147\n","test batch 1024 test_batch_hit:611 test_batch_char:648 batch_accuracy:94.290123\n","test batch 1040 test_batch_hit:663 test_batch_char:665 batch_accuracy:99.699248\n","test batch 1056 test_batch_hit:531 test_batch_char:554 batch_accuracy:95.848375\n","test batch 1072 test_batch_hit:833 test_batch_char:907 batch_accuracy:91.841235\n","test batch 1088 test_batch_hit:595 test_batch_char:620 batch_accuracy:95.967742\n","test batch 1104 test_batch_hit:911 test_batch_char:927 batch_accuracy:98.274002\n","test batch 1120 test_batch_hit:635 test_batch_char:656 batch_accuracy:96.798780\n","test batch 1136 test_batch_hit:543 test_batch_char:556 batch_accuracy:97.661871\n","test batch 1152 test_batch_hit:700 test_batch_char:723 batch_accuracy:96.818811\n","test batch 1168 test_batch_hit:748 test_batch_char:750 batch_accuracy:99.733333\n","test batch 1184 test_batch_hit:1147 test_batch_char:1169 batch_accuracy:98.118050\n","test batch 1200 test_batch_hit:521 test_batch_char:521 batch_accuracy:100.000000\n","test batch 1216 test_batch_hit:564 test_batch_char:564 batch_accuracy:100.000000\n","test batch 1232 test_batch_hit:664 test_batch_char:666 batch_accuracy:99.699700\n","test batch 1248 test_batch_hit:665 test_batch_char:667 batch_accuracy:99.700150\n","test batch 1264 test_batch_hit:797 test_batch_char:803 batch_accuracy:99.252802\n","test batch 1280 test_batch_hit:598 test_batch_char:613 batch_accuracy:97.553018\n","test batch 1296 test_batch_hit:643 test_batch_char:698 batch_accuracy:92.120344\n","test batch 1312 test_batch_hit:475 test_batch_char:488 batch_accuracy:97.336066\n","test batch 1328 test_batch_hit:494 test_batch_char:502 batch_accuracy:98.406375\n","test batch 1344 test_batch_hit:643 test_batch_char:657 batch_accuracy:97.869102\n","test batch 1360 test_batch_hit:754 test_batch_char:766 batch_accuracy:98.433420\n","test batch 1376 test_batch_hit:763 test_batch_char:784 batch_accuracy:97.321429\n","test batch 1392 test_batch_hit:580 test_batch_char:592 batch_accuracy:97.972973\n","test batch 1408 test_batch_hit:741 test_batch_char:753 batch_accuracy:98.406375\n","test batch 1424 test_batch_hit:935 test_batch_char:950 batch_accuracy:98.421053\n","test batch 1440 test_batch_hit:920 test_batch_char:929 batch_accuracy:99.031216\n","test batch 1456 test_batch_hit:901 test_batch_char:909 batch_accuracy:99.119912\n","test batch 1472 test_batch_hit:596 test_batch_char:604 batch_accuracy:98.675497\n","test batch 1488 test_batch_hit:604 test_batch_char:626 batch_accuracy:96.485623\n","test batch 1504 test_batch_hit:568 test_batch_char:605 batch_accuracy:93.884298\n","test batch 1520 test_batch_hit:668 test_batch_char:676 batch_accuracy:98.816568\n","test batch 1536 test_batch_hit:973 test_batch_char:973 batch_accuracy:100.000000\n","test batch 1552 test_batch_hit:933 test_batch_char:966 batch_accuracy:96.583851\n","test batch 1568 test_batch_hit:894 test_batch_char:920 batch_accuracy:97.173913\n","test batch 1584 test_batch_hit:980 test_batch_char:988 batch_accuracy:99.190283\n","test batch 1600 test_batch_hit:956 test_batch_char:970 batch_accuracy:98.556701\n","test batch 1616 test_batch_hit:1015 test_batch_char:1075 batch_accuracy:94.418605\n","test batch 1632 test_batch_hit:427 test_batch_char:442 batch_accuracy:96.606335\n","test batch 1648 test_batch_hit:595 test_batch_char:611 batch_accuracy:97.381342\n","test batch 1664 test_batch_hit:633 test_batch_char:652 batch_accuracy:97.085890\n","test batch 1680 test_batch_hit:642 test_batch_char:648 batch_accuracy:99.074074\n","test batch 1696 test_batch_hit:677 test_batch_char:679 batch_accuracy:99.705449\n","test batch 1712 test_batch_hit:602 test_batch_char:608 batch_accuracy:99.013158\n","test batch 1728 test_batch_hit:487 test_batch_char:503 batch_accuracy:96.819085\n","test batch 1744 test_batch_hit:597 test_batch_char:601 batch_accuracy:99.334443\n","test batch 1760 test_batch_hit:902 test_batch_char:912 batch_accuracy:98.903509\n","test batch 1776 test_batch_hit:750 test_batch_char:760 batch_accuracy:98.684211\n","test batch 1792 test_batch_hit:852 test_batch_char:867 batch_accuracy:98.269896\n","test batch 1808 test_batch_hit:754 test_batch_char:761 batch_accuracy:99.080158\n","test batch 1824 test_batch_hit:1030 test_batch_char:1044 batch_accuracy:98.659004\n","test batch 1840 test_batch_hit:854 test_batch_char:868 batch_accuracy:98.387097\n","test batch 1856 test_batch_hit:848 test_batch_char:859 batch_accuracy:98.719441\n","test batch 1872 test_batch_hit:650 test_batch_char:661 batch_accuracy:98.335855\n","test batch 1888 test_batch_hit:751 test_batch_char:780 batch_accuracy:96.282051\n","test batch 1904 test_batch_hit:1146 test_batch_char:1152 batch_accuracy:99.479167\n","test batch 1920 test_batch_hit:857 test_batch_char:897 batch_accuracy:95.540691\n","test batch 1936 test_batch_hit:924 test_batch_char:976 batch_accuracy:94.672131\n","test batch 1952 test_batch_hit:819 test_batch_char:844 batch_accuracy:97.037915\n","test batch 1968 test_batch_hit:676 test_batch_char:722 batch_accuracy:93.628809\n","test batch 1984 test_batch_hit:667 test_batch_char:681 batch_accuracy:97.944200\n","test batch 2000 test_batch_hit:968 test_batch_char:990 batch_accuracy:97.777778\n","test batch 2016 test_batch_hit:926 test_batch_char:928 batch_accuracy:99.784483\n","test batch 2032 test_batch_hit:854 test_batch_char:865 batch_accuracy:98.728324\n","test batch 2048 test_batch_hit:731 test_batch_char:759 batch_accuracy:96.310935\n","test batch 2064 test_batch_hit:735 test_batch_char:771 batch_accuracy:95.330739\n","test batch 2080 test_batch_hit:679 test_batch_char:681 batch_accuracy:99.706314\n","test batch 2096 test_batch_hit:738 test_batch_char:749 batch_accuracy:98.531375\n","test batch 2112 test_batch_hit:698 test_batch_char:710 batch_accuracy:98.309859\n","test batch 2128 test_batch_hit:860 test_batch_char:882 batch_accuracy:97.505669\n","test batch 2144 test_batch_hit:909 test_batch_char:919 batch_accuracy:98.911861\n","test batch 2160 test_batch_hit:538 test_batch_char:560 batch_accuracy:96.071429\n","test batch 2176 test_batch_hit:373 test_batch_char:377 batch_accuracy:98.938992\n","test batch 2192 test_batch_hit:481 test_batch_char:510 batch_accuracy:94.313725\n","test batch 2208 test_batch_hit:533 test_batch_char:552 batch_accuracy:96.557971\n","test batch 2224 test_batch_hit:760 test_batch_char:778 batch_accuracy:97.686375\n","test batch 2240 test_batch_hit:684 test_batch_char:696 batch_accuracy:98.275862\n","test batch 2256 test_batch_hit:559 test_batch_char:563 batch_accuracy:99.289520\n","test batch 2272 test_batch_hit:562 test_batch_char:575 batch_accuracy:97.739130\n","test batch 2288 test_batch_hit:490 test_batch_char:514 batch_accuracy:95.330739\n","test batch 2304 test_batch_hit:767 test_batch_char:789 batch_accuracy:97.211660\n","test batch 2320 test_batch_hit:782 test_batch_char:806 batch_accuracy:97.022333\n","test batch 2336 test_batch_hit:618 test_batch_char:621 batch_accuracy:99.516908\n","test batch 2352 test_batch_hit:736 test_batch_char:752 batch_accuracy:97.872340\n","test batch 2368 test_batch_hit:594 test_batch_char:612 batch_accuracy:97.058824\n","test batch 2384 test_batch_hit:847 test_batch_char:866 batch_accuracy:97.806005\n","test batch 2400 test_batch_hit:564 test_batch_char:564 batch_accuracy:100.000000\n","test batch 2416 test_batch_hit:740 test_batch_char:745 batch_accuracy:99.328859\n","test batch 2432 test_batch_hit:701 test_batch_char:711 batch_accuracy:98.593530\n","test batch 2448 test_batch_hit:723 test_batch_char:731 batch_accuracy:98.905609\n","test batch 2464 test_batch_hit:538 test_batch_char:544 batch_accuracy:98.897059\n","test batch 2480 test_batch_hit:955 test_batch_char:979 batch_accuracy:97.548519\n","test batch 2496 test_batch_hit:960 test_batch_char:991 batch_accuracy:96.871847\n","test batch 2512 test_batch_hit:809 test_batch_char:831 batch_accuracy:97.352587\n","test batch 2528 test_batch_hit:883 test_batch_char:930 batch_accuracy:94.946237\n","test batch 2544 test_batch_hit:712 test_batch_char:743 batch_accuracy:95.827725\n","test batch 2560 test_batch_hit:798 test_batch_char:810 batch_accuracy:98.518519\n","test batch 2576 test_batch_hit:1009 test_batch_char:1039 batch_accuracy:97.112608\n","test batch 2592 test_batch_hit:592 test_batch_char:610 batch_accuracy:97.049180\n","test batch 2608 test_batch_hit:659 test_batch_char:666 batch_accuracy:98.948949\n","test batch 2624 test_batch_hit:830 test_batch_char:868 batch_accuracy:95.622120\n","test batch 2640 test_batch_hit:602 test_batch_char:604 batch_accuracy:99.668874\n","test batch 2656 test_batch_hit:572 test_batch_char:585 batch_accuracy:97.777778\n","test batch 2672 test_batch_hit:587 test_batch_char:594 batch_accuracy:98.821549\n","test batch 2688 test_batch_hit:571 test_batch_char:573 batch_accuracy:99.650960\n","test batch 2704 test_batch_hit:1183 test_batch_char:1189 batch_accuracy:99.495374\n","test batch 2720 test_batch_hit:752 test_batch_char:762 batch_accuracy:98.687664\n","test batch 2736 test_batch_hit:468 test_batch_char:485 batch_accuracy:96.494845\n","test batch 2752 test_batch_hit:839 test_batch_char:859 batch_accuracy:97.671711\n","test batch 2768 test_batch_hit:806 test_batch_char:832 batch_accuracy:96.875000\n","test batch 2784 test_batch_hit:661 test_batch_char:671 batch_accuracy:98.509687\n","test batch 2800 test_batch_hit:818 test_batch_char:840 batch_accuracy:97.380952\n","test batch 2816 test_batch_hit:461 test_batch_char:486 batch_accuracy:94.855967\n","test batch 2832 test_batch_hit:456 test_batch_char:497 batch_accuracy:91.750503\n","test batch 2848 test_batch_hit:706 test_batch_char:747 batch_accuracy:94.511379\n","test batch 2864 test_batch_hit:577 test_batch_char:586 batch_accuracy:98.464164\n","test batch 2880 test_batch_hit:701 test_batch_char:709 batch_accuracy:98.871650\n","test batch 2896 test_batch_hit:855 test_batch_char:879 batch_accuracy:97.269625\n","test batch 2912 test_batch_hit:715 test_batch_char:725 batch_accuracy:98.620690\n","test batch 2928 test_batch_hit:436 test_batch_char:443 batch_accuracy:98.419865\n","test batch 2944 test_batch_hit:525 test_batch_char:529 batch_accuracy:99.243856\n","test batch 2960 test_batch_hit:914 test_batch_char:933 batch_accuracy:97.963558\n","test batch 2976 test_batch_hit:875 test_batch_char:884 batch_accuracy:98.981900\n","test batch 2992 test_batch_hit:573 test_batch_char:575 batch_accuracy:99.652174\n","test batch 3008 test_batch_hit:800 test_batch_char:814 batch_accuracy:98.280098\n","test batch 3024 test_batch_hit:686 test_batch_char:690 batch_accuracy:99.420290\n","test batch 3040 test_batch_hit:758 test_batch_char:780 batch_accuracy:97.179487\n","test batch 3056 test_batch_hit:703 test_batch_char:709 batch_accuracy:99.153738\n","test batch 3072 test_batch_hit:809 test_batch_char:813 batch_accuracy:99.507995\n","test batch 3088 test_batch_hit:889 test_batch_char:905 batch_accuracy:98.232044\n","test batch 3104 test_batch_hit:1004 test_batch_char:1013 batch_accuracy:99.111550\n","test batch 3120 test_batch_hit:616 test_batch_char:633 batch_accuracy:97.314376\n","test batch 3136 test_batch_hit:820 test_batch_char:830 batch_accuracy:98.795181\n","test batch 3152 test_batch_hit:943 test_batch_char:972 batch_accuracy:97.016461\n","test batch 3168 test_batch_hit:606 test_batch_char:629 batch_accuracy:96.343402\n","test batch 3184 test_batch_hit:635 test_batch_char:658 batch_accuracy:96.504559\n","test batch 3200 test_batch_hit:610 test_batch_char:621 batch_accuracy:98.228663\n","test batch 3216 test_batch_hit:655 test_batch_char:679 batch_accuracy:96.465390\n","test batch 3232 test_batch_hit:584 test_batch_char:612 batch_accuracy:95.424837\n","test batch 3248 test_batch_hit:776 test_batch_char:817 batch_accuracy:94.981640\n","test batch 3264 test_batch_hit:798 test_batch_char:854 batch_accuracy:93.442623\n","test batch 3280 test_batch_hit:669 test_batch_char:700 batch_accuracy:95.571429\n","test batch 3296 test_batch_hit:574 test_batch_char:578 batch_accuracy:99.307958\n","test batch 3312 test_batch_hit:729 test_batch_char:740 batch_accuracy:98.513514\n","test batch 3328 test_batch_hit:618 test_batch_char:626 batch_accuracy:98.722045\n","test batch 3344 test_batch_hit:780 test_batch_char:806 batch_accuracy:96.774194\n","test batch 3360 test_batch_hit:816 test_batch_char:850 batch_accuracy:96.000000\n","test batch 3376 test_batch_hit:925 test_batch_char:976 batch_accuracy:94.774590\n","test batch 3392 test_batch_hit:749 test_batch_char:792 batch_accuracy:94.570707\n","test batch 3408 test_batch_hit:628 test_batch_char:655 batch_accuracy:95.877863\n","test batch 3424 test_batch_hit:845 test_batch_char:890 batch_accuracy:94.943820\n","test batch 3440 test_batch_hit:772 test_batch_char:805 batch_accuracy:95.900621\n","test batch 3456 test_batch_hit:535 test_batch_char:566 batch_accuracy:94.522968\n","test batch 3472 test_batch_hit:617 test_batch_char:637 batch_accuracy:96.860283\n","test batch 3488 test_batch_hit:728 test_batch_char:754 batch_accuracy:96.551724\n","test batch 3504 test_batch_hit:535 test_batch_char:553 batch_accuracy:96.745027\n","test batch 3520 test_batch_hit:570 test_batch_char:589 batch_accuracy:96.774194\n","test batch 3536 test_batch_hit:472 test_batch_char:487 batch_accuracy:96.919918\n","test batch 3552 test_batch_hit:481 test_batch_char:490 batch_accuracy:98.163265\n","test batch 3568 test_batch_hit:755 test_batch_char:786 batch_accuracy:96.055980\n","test batch 3584 test_batch_hit:718 test_batch_char:734 batch_accuracy:97.820163\n","test batch 3600 test_batch_hit:893 test_batch_char:912 batch_accuracy:97.916667\n","test batch 3616 test_batch_hit:862 test_batch_char:881 batch_accuracy:97.843360\n","test batch 3632 test_batch_hit:827 test_batch_char:839 batch_accuracy:98.569726\n","test batch 3648 test_batch_hit:1054 test_batch_char:1077 batch_accuracy:97.864438\n","test batch 3664 test_batch_hit:892 test_batch_char:899 batch_accuracy:99.221357\n","test batch 3680 test_batch_hit:958 test_batch_char:966 batch_accuracy:99.171843\n","test batch 3696 test_batch_hit:958 test_batch_char:968 batch_accuracy:98.966942\n","test batch 3712 test_batch_hit:681 test_batch_char:699 batch_accuracy:97.424893\n","test batch 3728 test_batch_hit:926 test_batch_char:932 batch_accuracy:99.356223\n","test batch 3744 test_batch_hit:940 test_batch_char:959 batch_accuracy:98.018770\n","test batch 3760 test_batch_hit:782 test_batch_char:800 batch_accuracy:97.750000\n","test batch 3776 test_batch_hit:642 test_batch_char:648 batch_accuracy:99.074074\n","test batch 3792 test_batch_hit:775 test_batch_char:790 batch_accuracy:98.101266\n","test batch 3808 test_batch_hit:487 test_batch_char:502 batch_accuracy:97.011952\n","test batch 3824 test_batch_hit:663 test_batch_char:674 batch_accuracy:98.367953\n","test batch 3840 test_batch_hit:665 test_batch_char:684 batch_accuracy:97.222222\n","test batch 3856 test_batch_hit:593 test_batch_char:625 batch_accuracy:94.880000\n","test batch 3872 test_batch_hit:462 test_batch_char:479 batch_accuracy:96.450939\n","test batch 3888 test_batch_hit:817 test_batch_char:823 batch_accuracy:99.270960\n","test batch 3904 test_batch_hit:842 test_batch_char:863 batch_accuracy:97.566628\n","test batch 3920 test_batch_hit:867 test_batch_char:878 batch_accuracy:98.747153\n","test batch 3936 test_batch_hit:517 test_batch_char:549 batch_accuracy:94.171220\n","test batch 3952 test_batch_hit:915 test_batch_char:941 batch_accuracy:97.236982\n","test batch 3968 test_batch_hit:738 test_batch_char:750 batch_accuracy:98.400000\n","test batch 3984 test_batch_hit:62 test_batch_char:68 batch_accuracy:91.176471\n","test_hit:179959 test_all_char:184355 accuracy:97.615470\n","--------------------------------------------\n","accuracy is: 97.615470\n","Model saved in path: /content/gdrive/My Drive/NLPHW1/best_model_path97.61547015269453/model.ckpt\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"xF76xnB8PT0C","colab":{}},"cell_type":"code","source":["# !tensorboard --logdir logging"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"e3BJElHb5vjI"},"cell_type":"markdown","source":["***Predicting Section***"]},{"metadata":{"colab_type":"code","id":"yP4JjtbsqBK6","outputId":"a440318b-c89a-4b91-e465-2bd4bf84742f","executionInfo":{"status":"error","timestamp":1555972963346,"user_tz":-120,"elapsed":18024,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"colab":{"base_uri":"https://localhost:8080/","height":2060}},"cell_type":"code","source":["#Restore Saved Tensorflow model.\n","\n","import tensorflow as tf\n","\n","with tf.Session() as sess:\n","    #saver = tf.train.Saver()\n","    \n","    new_saver = tf.train.import_meta_graph( root_path+'best_model_path/best_model_path97.417_100K_subsetEp5/model.ckpt.meta')\n","    new_saver.restore(sess, root_path+'best_model_path/best_model_path97.417_100K_subsetEp5/model.ckpt')\n","    print(\"Model restored.\")\n","        \n","   # for tensor in tf.get_default_graph().get_operations():\n","    #    print(tensor.name)\n","    \n","    test_hit_all=0\n","    test_all_char=0        \n","    test_pred = []\n","    for i in range(0, len(test_x), BATCH_SIZE):\n","        batch_x = test_x[slice(i, i + BATCH_SIZE)]\n","        batch_x = padding3(batch_x, PAD_ID)\n","\n","        lengths,unary_scores,transition_param_other = sess.run(\n","            [seq_length,output,transition_params], feed_dict = {X:batch_x, dropout_keep_prob:1.0})\n","        predict=[]\n","        for unary_score,length in zip(unary_scores,lengths):\n","            if length > 0 :\n","                viterbi_sequence, _=crf.viterbi_decode(unary_score[:length],transition_param_other)\n","                predict.append(viterbi_sequence)\n","            else:\n","                predict.append(\"\")\n","            #print('sentence length : %d' % (length))\n","            #print(viterbi_sequence)\n","        test_pred += predict \n","\n","        test_batch_hit,test_batch_char = number_of_batch_hits(predict, test_y[slice(i, i + BATCH_SIZE)])            \n","        print('test batch %d test_batch_hit:%d test_batch_char:%d batch_accuracy:%f' % (i, test_batch_hit, test_batch_char,(test_batch_hit/test_batch_char)*100 ))\n","        test_hit_all+=test_batch_hit\n","        test_all_char+=test_batch_char\n","\n","    test_acc = (test_hit_all/test_all_char)*100\n","    print('test_hit:%d test_all_char:%d accuracy:%f' % (test_hit_all,test_all_char,test_acc ))\n","    print(\"--------------------------------------------\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/NLPHW1/best_model_path/best_model_path97.417_100K_subsetEp5/model.ckpt\n","Model restored.\n"],"name":"stdout"},{"output_type":"error","ename":"FailedPreconditionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value loss/transitions\n\t [[{{node loss/transitions}}]]\n\t [[{{node Sum}}]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-17bbdb7f3621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         lengths,unary_scores,transition_param_other = sess.run(\n\u001b[0;32m---> 21\u001b[0;31m             [seq_length,output,transition_params], feed_dict = {X:batch_x, dropout_keep_prob:1.0})\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0munary_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value loss/transitions\n\t [[node loss/transitions (defined at <ipython-input-15-84ea786d31d9>:60) ]]\n\t [[node Sum (defined at <ipython-input-15-84ea786d31d9>:12) ]]\n\nCaused by op 'loss/transitions', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-6e46d071fd1a>\", line 1, in <module>\n    X, labels, output, train_op, dropout_keep_prob, loss, transition_params, seq_length = create_tensorflow_model(VOCAB_SIZE, WORD_EMBEDDING_DIM, HIDDEN_LAYER_DIM)\n  File \"<ipython-input-15-84ea786d31d9>\", line 60, in create_tensorflow_model\n    output, labels, seq_length)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/crf/python/ops/crf.py\", line 254, in crf_log_likelihood\n    transition_params = vs.get_variable(\"transitions\", [num_tags, num_tags])\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1509, in _init_from_args\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\", line 79, in variable_op_v2\n    shared_name=shared_name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 1425, in variable_v2\n    shared_name=shared_name, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value loss/transitions\n\t [[node loss/transitions (defined at <ipython-input-15-84ea786d31d9>:60) ]]\n\t [[node Sum (defined at <ipython-input-15-84ea786d31d9>:12) ]]\n"]}]},{"metadata":{"colab_type":"code","id":"4r5sXitKrcPq","colab":{}},"cell_type":"code","source":["#function for creating BIES file from id's and saving it as utf8 file\n","def ids_to_tag_file(test_pred,output_file):\n","    with codecs.open(output_file, 'w','utf-8') as f:\n","        for i in range(len(test_pred)):\n","            tag_list = ''\n","            for j in range(len(test_pred[i])):\n","                if test_pred[i][j]==0:\n","                    tag_list +='B'\n","                elif test_pred[i][j]==1:\n","                    tag_list+='I'\n","                elif test_pred[i][j]==2:\n","                    tag_list+='E'\n","                elif test_pred[i][j]==3:\n","                    tag_list+='S'\n","            f.write(''.join(tag_list).strip())            \n","            f.write('\\n') \n","    print(\"result is ready ...\")\n","   \n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1555773316841,"user_tz":-120,"elapsed":1425,"user":{"displayName":"manoochehr joodi bigdello","photoUrl":"https://lh3.googleusercontent.com/-XD-6qRYDvBg/AAAAAAAAAAI/AAAAAAAAAAc/KXU2VRoZa6s/s64/photo.jpg","userId":"07183045139148849434"}},"id":"XdxLm-JDXOCl","outputId":"2c686542-f1ec-4ec2-f47d-d2f0aa26f325","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["ids_to_tag_file(test_pred,output_file=root_path+'Datasets/cleaned_data/pku/bies/result.utf8')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["result is ready ...\n"],"name":"stdout"}]}]}